{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸ”¥ _DeepFire_: API Project for Fire Detection ðŸ”¥\n",
    "\n",
    "In this project, you'll apply your skills at neural network development in a new way: taking a model that you've trained yourself and deploying it to a static webpage that you can work with to upload new images and get prediction accuracy results. \n",
    "\n",
    "This project will primarily focus on your abilities in creating and testing neural network architecture development. \n",
    "\n",
    "#### **Specifically, you'll be creating a convolutional neural network that can ingest Fire Detection Image Data and predict binary class values, similarly to what we've done with multilayer perceptrons in the past.**\n",
    "\n",
    "Boilerplate and supporting architectures have been provided for a multitude of tasks ranging from data preprocessing, processing, ingestion, and predictive assessment â€“Â however, major tasks and design work will ultimately be left to you to approach and figure out ideal, optimized solutions. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ðŸ”¹ General Importations\n",
    "\n",
    "As always, we'll start with importing basic tools and functions for our task."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import utils\n",
    "\n",
    "import os, PIL\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()\n",
    "\n",
    "print(tf.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.6.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-07 14:10:57.650844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-07 14:10:57.705944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-07 14:10:57.706720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### ðŸ”Ž Initializing Deep Learning Tools ðŸ”\n",
    "\n",
    "---\n",
    "\n",
    "> Your first task will be crucial to ensuring the successful implementation of the rest of your notebook. \n",
    "> \n",
    "> **Initialize each line with the correct function type from the TensorFlow documentation.**\n",
    "> \n",
    "> Feel free to refer throughout the notebook and across previous notebooks to see which TensorFlow architectures you've used for similar tasks. \n",
    "> \n",
    "> To give you a guide for how this should look, you've been provided with a single correct function declaration in the form of `image_dataset_from_directory` at the end of the cell. \n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\" Sequential Model Architecture \"\"\"\n",
    "Sequential = tf.keras.models.Sequential\n",
    "\n",
    "\"\"\" Data Preprocessing Functions \"\"\"\n",
    "Resizing = tf.keras.layers.experimental.preprocessing.Resizing\n",
    "Rescaling = tf.keras.layers.experimental.preprocessing.Rescaling\n",
    "\n",
    "\"\"\" Data Augmentation Functions \"\"\"\n",
    "RandomFlip = tf.keras.layers.experimental.preprocessing.RandomFlip\n",
    "RandomRotation = tf.keras.layers.experimental.preprocessing.RandomRotation\n",
    "RandomZoom = tf.keras.layers.experimental.preprocessing.RandomZoom\n",
    "\n",
    "\"\"\" Artificial Neural Network Layer Inventory \"\"\"\n",
    "Dense = tf.keras.layers.Dense\n",
    "Dropout = tf.keras.layers.Dropout\n",
    "\n",
    "\"\"\" Convolutional Neural Network Layer Inventory \"\"\"\n",
    "Conv2D = tf.keras.layers.Conv2D\n",
    "MaxPool2D = tf.keras.layers.MaxPool2D\n",
    "Flatten = tf.keras.layers.Flatten\n",
    "\n",
    "\"\"\" Residual Network Layer Inventory \"\"\"\n",
    "ResNet50 = tf.keras.applications.ResNet50\n",
    "\n",
    "\"\"\" Function to Load Images from Target Folder \"\"\"\n",
    "image_dataset_from_directory = tf.keras.preprocessing.image_dataset_from_directory"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ðŸ”¹ Precheck Image Dataset Sizes\n",
    "\n",
    "If you've followed instructions carefully from the `project/PROJECT.md` instructions, the following dataset directory instantiations should work perfectly. \n",
    "\n",
    "If they do not, double-check to make sure you've saved your dataset to the appropriate location. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Use the `glob.glob` function to show how many images are in each folder\n",
    "DATA_DIRECTORY = \"../dataset/\"\n",
    "FIRE_IMAGES_PATTERN = f\"{DATA_DIRECTORY}/Fire_Images/*\"\n",
    "NOT_FIRE_IMAGES_PATTERN = f\"{DATA_DIRECTORY}/Normal_Images/*\"\n",
    "\n",
    "print(f\"Number of fire image samples: {len(glob(FIRE_IMAGES_PATTERN))}\")\n",
    "print(f\"Number of non-fire image samples: {len(glob(NOT_FIRE_IMAGES_PATTERN))}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of fire image samples: 541\n",
      "Number of non-fire image samples: 541\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ðŸ”¸ Load Dataset\n",
    "\n",
    "Like we've done previously, let's set our batch size and image dimensions to work seamlessly with our configured model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch_size = 32\n",
    "IMAGE_HEIGHT = IMAGE_WIDTH = 256"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train = image_dataset_from_directory(\n",
    "    directory=DATA_DIRECTORY,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1082 files belonging to 2 classes.\n",
      "Using 866 files for training.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-07 14:11:08.041770: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-07 14:11:08.044378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-07 14:11:08.045041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-07 14:11:08.045507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-07 14:11:08.804179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-07 14:11:08.804642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-07 14:11:08.804776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2021-10-07 14:11:08.805070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-10-07 14:11:08.805257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21642 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class_names = train.class_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "validation = image_dataset_from_directory(\n",
    "    directory=DATA_DIRECTORY,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1082 files belonging to 2 classes.\n",
      "Using 216 files for validation.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "From these results, we can actually see that we have a major class imbalance with our fire images representing our minority class. \n",
    "\n",
    "Let's go ahead and fix that by resampling our dataset. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ðŸ”¹ Resample (Oversample) Minority Class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def resample_class_distribution(train, DATA_DIRECTORY=DATA_DIRECTORY, save=True):\n",
    "    \"\"\" Helper function to resample class distribution for image dataset. \"\"\"\n",
    "    minority_class, majority_class = list(), list()\n",
    "    for images, labels, in train.take(3):\n",
    "        for image, label in zip(images, labels):\n",
    "            if label == 0:\n",
    "                minority_class.append(image.numpy().astype(np.uint8))\n",
    "            else:\n",
    "                majority_class.append(image.numpy().astype(np.uint8))\n",
    "    FIRE_SIZE = len(glob(f\"{DATA_DIRECTORY}/Fire_Images/*\"))\n",
    "    NOT_FIRE_SIZE = len(glob(f\"{DATA_DIRECTORY}/Normal_Images/*\"))\n",
    "    upsampled_images = np.array(utils.resample(minority_class, replace=True, \n",
    "                                               n_samples=(NOT_FIRE_SIZE - FIRE_SIZE),\n",
    "                                               random_state=42))\n",
    "    if save == True:\n",
    "        index = 0\n",
    "        for image in upsampled_images:\n",
    "            PATH = f\"{DATA_DIRECTORY}/Fire_Images/new_fire_{index}.png\"\n",
    "            PIL.Image.fromarray(image).save(PATH)\n",
    "            index += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "resample_class_distribution(train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-07 11:56:30.607296: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You should now see that additional images have been generated to balance out both classes prior to predictive modeling.\n",
    "\n",
    "**Go ahead and re-run the `Load Dataset` steps to see new generated dataset changes.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ðŸ”¹ Pre-Optimize Image File Ingestion\n",
    "\n",
    "This is an accessory step to optimize image data ingestion at the cost of slightly higher memory usage. No modifications are required for this function. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def configure_performant_datasets(dataset, shuffling=None):\n",
    "    \"\"\" \n",
    "    Custom function to prefetch and cache stored elements\n",
    "    of retrieved image data to boost latency and performance\n",
    "    at the cost of higher memory usage. \n",
    "    \"\"\"\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    # Cache and prefetch elements of input data for boosted performance\n",
    "    if not shuffling:\n",
    "        return dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    else:\n",
    "        return dataset.cache().shuffle(shuffling).prefetch(buffer_size=AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train =         configure_performant_datasets(train, shuffling=1000)\n",
    "validation =    configure_performant_datasets(validation)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### ðŸ”Ž Create Resizing and Normalization Layers ðŸ”\n",
    "\n",
    "---\n",
    "\n",
    "> For this task, you'll declare your resizing and normalization layers using the layer architectures that you imported earlier. \n",
    ">\n",
    "> Recall that for this step, we want to accomplish two key tasks: \n",
    "> - Resize all images to the predetermined square image dimensions as indicated by `IMAGE_HEIGHT` and `IMAGE_WIDTH`.\n",
    "> - Scale all images so pixel values are within the range of (0., 1.) rather than the original (0., 255.).\n",
    ">\n",
    "> Additionally, since we're working with colorized image data, we'll want to ensure that our image rescaling/normalization step inputs images as stacks-of-three, since each image channel corresponds to red, green, and blue pixel values. \n",
    ">\n",
    "> As always, refer to previous notebook documentation on image normalization for colorization if you need help.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "resizing_layer = Resizing(IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "normalization_layer = Rescaling(1./255, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### ðŸ”Ž Neural Network Architecture Creation ðŸ”\n",
    "\n",
    "---\n",
    "\n",
    "> Now time for the main event! \n",
    "> \n",
    "> Here, you'll be creating and instantiating your model architecture. \n",
    "> \n",
    "> For this assignment, you'll be creating a **Convolutional Neural Network** that can process Fire Detection images for predictive purposes.\n",
    "> \n",
    "> _For this project, you will not be provided guidance as to how to design and implement your CNN architecture._\n",
    "> \n",
    "> Refer to previous notebooks and challenges on CNNs as well as online documentation/resources for how to design CNN models on higher-order images. \n",
    "> \n",
    "> **This is a highly creative step, and there are no wrong answers; however, you will be assessed on your experimentation process and why you choose specific modeling layers, configurations, optimizers, regularizers, and overall design choices.**\n",
    ">\n",
    "> Light boilerplate will be provided to get you started, but as always, use any and all resources at your disposal to finish the job! \n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\"\"\" Sequential Model Architecture Setup \"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "\"\"\" CNN Layering Steps \"\"\"\n",
    "input_layer = tf.keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "flattening_layer = Flatten()\n",
    "dropout_layer = Dropout(0.33)\n",
    "conv2d_layer_1 = Conv2D(32, (3, 3), activation=\"relu\")\n",
    "conv2d_layer_2 = Conv2D(64, (3, 3), activation=\"relu\")\n",
    "conv2d_layer_3 = Conv2D(128, (3, 3), activation=\"relu\")\n",
    "pooling_layer_1, pooling_layer_2, pooling_layer_3 = MaxPool2D(), MaxPool2D(), MaxPool2D()\n",
    "dense_layer_1 = Dense(128, activation=\"relu\")\n",
    "dense_layer_2 = Dense(64, activation=\"relu\")\n",
    "dense_layer_3 = Dense(32, activation=\"relu\")\n",
    "output_layer = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "augmentation_layer = Sequential(\n",
    "    [\n",
    "        input_layer,\n",
    "        RandomFlip(\"horizontal_and_vertical\"),\n",
    "        RandomRotation(0.133),\n",
    "        RandomZoom(0.133),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model.add(input_layer)\n",
    "\n",
    "model.add(augmentation_layer)\n",
    "model.add(resizing_layer)\n",
    "model.add(normalization_layer)\n",
    "\n",
    "model.add(conv2d_layer_1)\n",
    "model.add(pooling_layer_1)\n",
    "model.add(conv2d_layer_2)\n",
    "model.add(pooling_layer_2)\n",
    "model.add(conv2d_layer_3)\n",
    "model.add(pooling_layer_3)\n",
    "\n",
    "model.add(flattening_layer)\n",
    "\n",
    "model.add(dense_layer_1)\n",
    "model.add(dense_layer_2)\n",
    "model.add(dropout_layer)\n",
    "model.add(dense_layer_3)\n",
    "\n",
    "model.add(output_layer)\n",
    "\n",
    "\"\"\" CNN Architecture Summarization \"\"\"\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "resizing (Resizing)          (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               14745728  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 14,849,345\n",
      "Trainable params: 14,849,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### ðŸ”Ž Neural Network Configuration ðŸ”\n",
    "\n",
    "---\n",
    "\n",
    "> For this task, you'll compile your CNN architecture with appropriate parameters for loss calculation, optimization, and accuracy metrics.\n",
    "> \n",
    "> As always, refer to previous notebooks, tutorials, and documentation for best-case parameters to use for image recognition models.\n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "\"\"\" CNN Model Compilation \"\"\"\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### ðŸ”Ž CNN Model Predictive Fitness ðŸ”\n",
    "\n",
    "---\n",
    "\n",
    "> For this task, you'll be taking your compiled model and fitting it against your training and validation data.\n",
    "> \n",
    "> Keep in mind that there are several opportunities for further optimizing your workflow with techniques such as batch normalization, generator-based data feeding, etc. \n",
    "> \n",
    "> As always, refer to previous notebooks, tutorials, and documentation for designing model fitness with validation data. \n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\"\"\" CNN Model Fitness and History Extraction \"\"\"\n",
    "epochs = 1000\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=validation,\n",
    "    epochs=epochs,\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-07 14:11:34.885128: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-07 14:11:36.606809: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n",
      "2021-10-07 14:11:37.752246: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2021-10-07 14:11:38.891813: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "28/28 [==============================] - 7s 55ms/step - loss: 0.6685 - accuracy: 0.6640 - val_loss: 0.6091 - val_accuracy: 0.7361\n",
      "Epoch 2/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.5615 - accuracy: 0.7564 - val_loss: 0.5240 - val_accuracy: 0.7500\n",
      "Epoch 3/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4992 - accuracy: 0.7771 - val_loss: 0.4888 - val_accuracy: 0.7870\n",
      "Epoch 4/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4791 - accuracy: 0.7852 - val_loss: 0.4875 - val_accuracy: 0.7870\n",
      "Epoch 5/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4599 - accuracy: 0.7968 - val_loss: 0.4260 - val_accuracy: 0.8148\n",
      "Epoch 6/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4620 - accuracy: 0.7910 - val_loss: 0.3851 - val_accuracy: 0.8009\n",
      "Epoch 7/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.4205 - accuracy: 0.8164 - val_loss: 0.3543 - val_accuracy: 0.8287\n",
      "Epoch 8/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.4028 - accuracy: 0.8245 - val_loss: 0.3348 - val_accuracy: 0.8380\n",
      "Epoch 9/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.3773 - accuracy: 0.8476 - val_loss: 0.3088 - val_accuracy: 0.8935\n",
      "Epoch 10/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.3326 - accuracy: 0.8637 - val_loss: 0.2725 - val_accuracy: 0.8981\n",
      "Epoch 11/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.3512 - accuracy: 0.8499 - val_loss: 0.2577 - val_accuracy: 0.8935\n",
      "Epoch 12/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.3025 - accuracy: 0.8811 - val_loss: 0.2323 - val_accuracy: 0.9028\n",
      "Epoch 13/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.3043 - accuracy: 0.8799 - val_loss: 0.2127 - val_accuracy: 0.9213\n",
      "Epoch 14/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2835 - accuracy: 0.8961 - val_loss: 0.2228 - val_accuracy: 0.9444\n",
      "Epoch 15/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.2646 - accuracy: 0.9076 - val_loss: 0.1977 - val_accuracy: 0.9259\n",
      "Epoch 16/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2554 - accuracy: 0.9042 - val_loss: 0.2021 - val_accuracy: 0.9213\n",
      "Epoch 17/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2478 - accuracy: 0.9042 - val_loss: 0.1953 - val_accuracy: 0.9167\n",
      "Epoch 18/1000\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.2399 - accuracy: 0.9134 - val_loss: 0.1765 - val_accuracy: 0.9444\n",
      "Epoch 19/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2452 - accuracy: 0.9076 - val_loss: 0.1753 - val_accuracy: 0.9259\n",
      "Epoch 20/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.2227 - accuracy: 0.9157 - val_loss: 0.1580 - val_accuracy: 0.9444\n",
      "Epoch 21/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.2266 - accuracy: 0.9122 - val_loss: 0.1525 - val_accuracy: 0.9444\n",
      "Epoch 22/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2115 - accuracy: 0.9273 - val_loss: 0.1528 - val_accuracy: 0.9398\n",
      "Epoch 23/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1994 - accuracy: 0.9319 - val_loss: 0.1757 - val_accuracy: 0.9259\n",
      "Epoch 24/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.2315 - accuracy: 0.9192 - val_loss: 0.1297 - val_accuracy: 0.9398\n",
      "Epoch 25/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.2017 - accuracy: 0.9330 - val_loss: 0.1449 - val_accuracy: 0.9491\n",
      "Epoch 26/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.2030 - accuracy: 0.9284 - val_loss: 0.1891 - val_accuracy: 0.9167\n",
      "Epoch 27/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.2002 - accuracy: 0.9342 - val_loss: 0.1464 - val_accuracy: 0.9491\n",
      "Epoch 28/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.2106 - accuracy: 0.9238 - val_loss: 0.1493 - val_accuracy: 0.9398\n",
      "Epoch 29/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.2080 - accuracy: 0.9330 - val_loss: 0.1365 - val_accuracy: 0.9352\n",
      "Epoch 30/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1720 - accuracy: 0.9434 - val_loss: 0.1524 - val_accuracy: 0.9444\n",
      "Epoch 31/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1760 - accuracy: 0.9400 - val_loss: 0.1597 - val_accuracy: 0.9306\n",
      "Epoch 32/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1714 - accuracy: 0.9353 - val_loss: 0.1410 - val_accuracy: 0.9444\n",
      "Epoch 33/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1758 - accuracy: 0.9446 - val_loss: 0.1505 - val_accuracy: 0.9491\n",
      "Epoch 34/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1857 - accuracy: 0.9376 - val_loss: 0.1304 - val_accuracy: 0.9352\n",
      "Epoch 35/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1624 - accuracy: 0.9446 - val_loss: 0.1155 - val_accuracy: 0.9537\n",
      "Epoch 36/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1797 - accuracy: 0.9434 - val_loss: 0.1173 - val_accuracy: 0.9398\n",
      "Epoch 37/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1738 - accuracy: 0.9353 - val_loss: 0.1246 - val_accuracy: 0.9537\n",
      "Epoch 38/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1707 - accuracy: 0.9503 - val_loss: 0.1240 - val_accuracy: 0.9583\n",
      "Epoch 39/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1533 - accuracy: 0.9469 - val_loss: 0.1280 - val_accuracy: 0.9537\n",
      "Epoch 40/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1855 - accuracy: 0.9423 - val_loss: 0.1549 - val_accuracy: 0.9583\n",
      "Epoch 41/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1699 - accuracy: 0.9446 - val_loss: 0.1132 - val_accuracy: 0.9537\n",
      "Epoch 42/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1620 - accuracy: 0.9469 - val_loss: 0.1358 - val_accuracy: 0.9491\n",
      "Epoch 43/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1785 - accuracy: 0.9411 - val_loss: 0.1162 - val_accuracy: 0.9444\n",
      "Epoch 44/1000\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1826 - accuracy: 0.9400 - val_loss: 0.1307 - val_accuracy: 0.9491\n",
      "Epoch 45/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1785 - accuracy: 0.9388 - val_loss: 0.1146 - val_accuracy: 0.9444\n",
      "Epoch 46/1000\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1409 - accuracy: 0.9527 - val_loss: 0.1110 - val_accuracy: 0.9398\n",
      "Epoch 47/1000\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.1879 - accuracy: 0.9457 - val_loss: 0.1195 - val_accuracy: 0.9537\n",
      "Epoch 48/1000\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.1717 - accuracy: 0.9423 - val_loss: 0.1185 - val_accuracy: 0.9444\n",
      "Epoch 49/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1413 - accuracy: 0.9480 - val_loss: 0.1457 - val_accuracy: 0.9444\n",
      "Epoch 50/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1661 - accuracy: 0.9446 - val_loss: 0.1122 - val_accuracy: 0.9444\n",
      "Epoch 51/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1444 - accuracy: 0.9550 - val_loss: 0.1316 - val_accuracy: 0.9398\n",
      "Epoch 52/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1322 - accuracy: 0.9515 - val_loss: 0.1338 - val_accuracy: 0.9537\n",
      "Epoch 53/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1520 - accuracy: 0.9457 - val_loss: 0.1159 - val_accuracy: 0.9537\n",
      "Epoch 54/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1456 - accuracy: 0.9446 - val_loss: 0.1147 - val_accuracy: 0.9537\n",
      "Epoch 55/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1631 - accuracy: 0.9434 - val_loss: 0.1264 - val_accuracy: 0.9352\n",
      "Epoch 56/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1586 - accuracy: 0.9400 - val_loss: 0.1208 - val_accuracy: 0.9537\n",
      "Epoch 57/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1497 - accuracy: 0.9480 - val_loss: 0.1206 - val_accuracy: 0.9583\n",
      "Epoch 58/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1352 - accuracy: 0.9527 - val_loss: 0.1033 - val_accuracy: 0.9583\n",
      "Epoch 59/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1346 - accuracy: 0.9480 - val_loss: 0.1006 - val_accuracy: 0.9583\n",
      "Epoch 60/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1509 - accuracy: 0.9584 - val_loss: 0.1215 - val_accuracy: 0.9491\n",
      "Epoch 61/1000\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.1320 - accuracy: 0.9573 - val_loss: 0.1109 - val_accuracy: 0.9537\n",
      "Epoch 62/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1423 - accuracy: 0.9503 - val_loss: 0.1458 - val_accuracy: 0.9398\n",
      "Epoch 63/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1267 - accuracy: 0.9469 - val_loss: 0.1189 - val_accuracy: 0.9491\n",
      "Epoch 64/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1329 - accuracy: 0.9561 - val_loss: 0.1269 - val_accuracy: 0.9444\n",
      "Epoch 65/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1328 - accuracy: 0.9573 - val_loss: 0.1154 - val_accuracy: 0.9444\n",
      "Epoch 66/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1389 - accuracy: 0.9492 - val_loss: 0.1090 - val_accuracy: 0.9491\n",
      "Epoch 67/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1252 - accuracy: 0.9527 - val_loss: 0.1648 - val_accuracy: 0.9398\n",
      "Epoch 68/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1234 - accuracy: 0.9596 - val_loss: 0.1795 - val_accuracy: 0.9306\n",
      "Epoch 69/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1368 - accuracy: 0.9503 - val_loss: 0.1013 - val_accuracy: 0.9537\n",
      "Epoch 70/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1398 - accuracy: 0.9434 - val_loss: 0.1117 - val_accuracy: 0.9537\n",
      "Epoch 71/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1400 - accuracy: 0.9446 - val_loss: 0.1095 - val_accuracy: 0.9537\n",
      "Epoch 72/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1425 - accuracy: 0.9550 - val_loss: 0.1050 - val_accuracy: 0.9583\n",
      "Epoch 73/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1195 - accuracy: 0.9550 - val_loss: 0.1115 - val_accuracy: 0.9537\n",
      "Epoch 74/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1314 - accuracy: 0.9584 - val_loss: 0.1427 - val_accuracy: 0.9583\n",
      "Epoch 75/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1165 - accuracy: 0.9607 - val_loss: 0.1082 - val_accuracy: 0.9676\n",
      "Epoch 76/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1023 - accuracy: 0.9654 - val_loss: 0.1267 - val_accuracy: 0.9491\n",
      "Epoch 77/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1342 - accuracy: 0.9503 - val_loss: 0.1265 - val_accuracy: 0.9398\n",
      "Epoch 78/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1229 - accuracy: 0.9561 - val_loss: 0.1359 - val_accuracy: 0.9630\n",
      "Epoch 79/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1259 - accuracy: 0.9607 - val_loss: 0.0963 - val_accuracy: 0.9583\n",
      "Epoch 80/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1220 - accuracy: 0.9596 - val_loss: 0.1070 - val_accuracy: 0.9630\n",
      "Epoch 81/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1182 - accuracy: 0.9584 - val_loss: 0.1206 - val_accuracy: 0.9444\n",
      "Epoch 82/1000\n",
      "28/28 [==============================] - 1s 46ms/step - loss: 0.1252 - accuracy: 0.9573 - val_loss: 0.1278 - val_accuracy: 0.9583\n",
      "Epoch 83/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1117 - accuracy: 0.9584 - val_loss: 0.1095 - val_accuracy: 0.9630\n",
      "Epoch 84/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1094 - accuracy: 0.9654 - val_loss: 0.1167 - val_accuracy: 0.9491\n",
      "Epoch 85/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1228 - accuracy: 0.9561 - val_loss: 0.0968 - val_accuracy: 0.9583\n",
      "Epoch 86/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1175 - accuracy: 0.9596 - val_loss: 0.1187 - val_accuracy: 0.9491\n",
      "Epoch 87/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1077 - accuracy: 0.9619 - val_loss: 0.1063 - val_accuracy: 0.9630\n",
      "Epoch 88/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1073 - accuracy: 0.9665 - val_loss: 0.1397 - val_accuracy: 0.9583\n",
      "Epoch 89/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1142 - accuracy: 0.9550 - val_loss: 0.1068 - val_accuracy: 0.9491\n",
      "Epoch 90/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1010 - accuracy: 0.9642 - val_loss: 0.1245 - val_accuracy: 0.9491\n",
      "Epoch 91/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1145 - accuracy: 0.9561 - val_loss: 0.1056 - val_accuracy: 0.9583\n",
      "Epoch 92/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1160 - accuracy: 0.9607 - val_loss: 0.1001 - val_accuracy: 0.9583\n",
      "Epoch 93/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1021 - accuracy: 0.9573 - val_loss: 0.1149 - val_accuracy: 0.9676\n",
      "Epoch 94/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1013 - accuracy: 0.9700 - val_loss: 0.1157 - val_accuracy: 0.9537\n",
      "Epoch 95/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1242 - accuracy: 0.9596 - val_loss: 0.1597 - val_accuracy: 0.9583\n",
      "Epoch 96/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1062 - accuracy: 0.9584 - val_loss: 0.1410 - val_accuracy: 0.9491\n",
      "Epoch 97/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1040 - accuracy: 0.9630 - val_loss: 0.1134 - val_accuracy: 0.9583\n",
      "Epoch 98/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1038 - accuracy: 0.9619 - val_loss: 0.1942 - val_accuracy: 0.9306\n",
      "Epoch 99/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1207 - accuracy: 0.9469 - val_loss: 0.1102 - val_accuracy: 0.9537\n",
      "Epoch 100/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0931 - accuracy: 0.9700 - val_loss: 0.1264 - val_accuracy: 0.9444\n",
      "Epoch 101/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1055 - accuracy: 0.9607 - val_loss: 0.1061 - val_accuracy: 0.9630\n",
      "Epoch 102/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1079 - accuracy: 0.9619 - val_loss: 0.1028 - val_accuracy: 0.9583\n",
      "Epoch 103/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1025 - accuracy: 0.9642 - val_loss: 0.1031 - val_accuracy: 0.9583\n",
      "Epoch 104/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1015 - accuracy: 0.9688 - val_loss: 0.1069 - val_accuracy: 0.9583\n",
      "Epoch 105/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0896 - accuracy: 0.9677 - val_loss: 0.1227 - val_accuracy: 0.9583\n",
      "Epoch 106/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0996 - accuracy: 0.9619 - val_loss: 0.1164 - val_accuracy: 0.9630\n",
      "Epoch 107/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0969 - accuracy: 0.9630 - val_loss: 0.1330 - val_accuracy: 0.9537\n",
      "Epoch 108/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1122 - accuracy: 0.9584 - val_loss: 0.1110 - val_accuracy: 0.9537\n",
      "Epoch 109/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1174 - accuracy: 0.9619 - val_loss: 0.1110 - val_accuracy: 0.9630\n",
      "Epoch 110/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1186 - accuracy: 0.9654 - val_loss: 0.0843 - val_accuracy: 0.9630\n",
      "Epoch 111/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1121 - accuracy: 0.9654 - val_loss: 0.0831 - val_accuracy: 0.9630\n",
      "Epoch 112/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0970 - accuracy: 0.9654 - val_loss: 0.1068 - val_accuracy: 0.9537\n",
      "Epoch 113/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1104 - accuracy: 0.9654 - val_loss: 0.0940 - val_accuracy: 0.9583\n",
      "Epoch 114/1000\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0959 - accuracy: 0.9700 - val_loss: 0.1521 - val_accuracy: 0.9537\n",
      "Epoch 115/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1004 - accuracy: 0.9654 - val_loss: 0.1037 - val_accuracy: 0.9583\n",
      "Epoch 116/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0991 - accuracy: 0.9677 - val_loss: 0.1152 - val_accuracy: 0.9491\n",
      "Epoch 117/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0966 - accuracy: 0.9665 - val_loss: 0.1266 - val_accuracy: 0.9676\n",
      "Epoch 118/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0978 - accuracy: 0.9642 - val_loss: 0.1001 - val_accuracy: 0.9583\n",
      "Epoch 119/1000\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0855 - accuracy: 0.9723 - val_loss: 0.1090 - val_accuracy: 0.9630\n",
      "Epoch 120/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.1100 - val_accuracy: 0.9491\n",
      "Epoch 121/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.1023 - accuracy: 0.9630 - val_loss: 0.1138 - val_accuracy: 0.9537\n",
      "Epoch 122/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0900 - accuracy: 0.9677 - val_loss: 0.1431 - val_accuracy: 0.9537\n",
      "Epoch 123/1000\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0988 - accuracy: 0.9654 - val_loss: 0.1197 - val_accuracy: 0.9537\n",
      "Epoch 124/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1060 - accuracy: 0.9700 - val_loss: 0.1091 - val_accuracy: 0.9537\n",
      "Epoch 125/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0903 - accuracy: 0.9700 - val_loss: 0.1330 - val_accuracy: 0.9491\n",
      "Epoch 126/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0906 - accuracy: 0.9688 - val_loss: 0.0977 - val_accuracy: 0.9676\n",
      "Epoch 127/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0854 - accuracy: 0.9665 - val_loss: 0.1331 - val_accuracy: 0.9491\n",
      "Epoch 128/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0837 - accuracy: 0.9723 - val_loss: 0.1877 - val_accuracy: 0.9444\n",
      "Epoch 129/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0893 - accuracy: 0.9642 - val_loss: 0.1095 - val_accuracy: 0.9491\n",
      "Epoch 130/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0853 - accuracy: 0.9723 - val_loss: 0.1059 - val_accuracy: 0.9676\n",
      "Epoch 131/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0889 - accuracy: 0.9619 - val_loss: 0.1207 - val_accuracy: 0.9583\n",
      "Epoch 132/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1020 - accuracy: 0.9630 - val_loss: 0.1009 - val_accuracy: 0.9630\n",
      "Epoch 133/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0855 - accuracy: 0.9700 - val_loss: 0.1174 - val_accuracy: 0.9583\n",
      "Epoch 134/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0890 - accuracy: 0.9688 - val_loss: 0.0982 - val_accuracy: 0.9676\n",
      "Epoch 135/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0727 - accuracy: 0.9792 - val_loss: 0.1591 - val_accuracy: 0.9444\n",
      "Epoch 136/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0627 - accuracy: 0.9792 - val_loss: 0.1277 - val_accuracy: 0.9537\n",
      "Epoch 137/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0888 - accuracy: 0.9677 - val_loss: 0.1366 - val_accuracy: 0.9491\n",
      "Epoch 138/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0735 - accuracy: 0.9734 - val_loss: 0.0950 - val_accuracy: 0.9630\n",
      "Epoch 139/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0825 - accuracy: 0.9665 - val_loss: 0.1064 - val_accuracy: 0.9583\n",
      "Epoch 140/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0699 - accuracy: 0.9769 - val_loss: 0.1443 - val_accuracy: 0.9491\n",
      "Epoch 141/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0665 - accuracy: 0.9758 - val_loss: 0.1029 - val_accuracy: 0.9630\n",
      "Epoch 142/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0710 - accuracy: 0.9769 - val_loss: 0.1137 - val_accuracy: 0.9583\n",
      "Epoch 143/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0817 - accuracy: 0.9734 - val_loss: 0.1032 - val_accuracy: 0.9583\n",
      "Epoch 144/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0885 - accuracy: 0.9746 - val_loss: 0.1179 - val_accuracy: 0.9583\n",
      "Epoch 145/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0751 - accuracy: 0.9758 - val_loss: 0.1021 - val_accuracy: 0.9630\n",
      "Epoch 146/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0797 - accuracy: 0.9723 - val_loss: 0.1175 - val_accuracy: 0.9583\n",
      "Epoch 147/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0604 - accuracy: 0.9815 - val_loss: 0.2001 - val_accuracy: 0.9444\n",
      "Epoch 148/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0855 - accuracy: 0.9700 - val_loss: 0.1065 - val_accuracy: 0.9583\n",
      "Epoch 149/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0840 - accuracy: 0.9734 - val_loss: 0.1013 - val_accuracy: 0.9583\n",
      "Epoch 150/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0764 - accuracy: 0.9758 - val_loss: 0.0882 - val_accuracy: 0.9676\n",
      "Epoch 151/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0727 - accuracy: 0.9723 - val_loss: 0.0967 - val_accuracy: 0.9630\n",
      "Epoch 152/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0798 - accuracy: 0.9804 - val_loss: 0.1220 - val_accuracy: 0.9583\n",
      "Epoch 153/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0888 - accuracy: 0.9677 - val_loss: 0.1450 - val_accuracy: 0.9583\n",
      "Epoch 154/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0702 - accuracy: 0.9781 - val_loss: 0.0960 - val_accuracy: 0.9583\n",
      "Epoch 155/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 0.1167 - val_accuracy: 0.9537\n",
      "Epoch 156/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0826 - accuracy: 0.9781 - val_loss: 0.1238 - val_accuracy: 0.9444\n",
      "Epoch 157/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0902 - accuracy: 0.9665 - val_loss: 0.1010 - val_accuracy: 0.9676\n",
      "Epoch 158/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0624 - accuracy: 0.9746 - val_loss: 0.1333 - val_accuracy: 0.9537\n",
      "Epoch 159/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0842 - accuracy: 0.9723 - val_loss: 0.1131 - val_accuracy: 0.9630\n",
      "Epoch 160/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0618 - accuracy: 0.9781 - val_loss: 0.1269 - val_accuracy: 0.9583\n",
      "Epoch 161/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0664 - accuracy: 0.9792 - val_loss: 0.3414 - val_accuracy: 0.9120\n",
      "Epoch 162/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0762 - accuracy: 0.9700 - val_loss: 0.1097 - val_accuracy: 0.9630\n",
      "Epoch 163/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0654 - accuracy: 0.9781 - val_loss: 0.1215 - val_accuracy: 0.9583\n",
      "Epoch 164/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1302 - accuracy: 0.9607 - val_loss: 0.1012 - val_accuracy: 0.9630\n",
      "Epoch 165/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0693 - accuracy: 0.9758 - val_loss: 0.0894 - val_accuracy: 0.9630\n",
      "Epoch 166/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0821 - accuracy: 0.9723 - val_loss: 0.0952 - val_accuracy: 0.9583\n",
      "Epoch 167/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0679 - accuracy: 0.9792 - val_loss: 0.0992 - val_accuracy: 0.9537\n",
      "Epoch 168/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0763 - accuracy: 0.9688 - val_loss: 0.0996 - val_accuracy: 0.9630\n",
      "Epoch 169/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0795 - accuracy: 0.9723 - val_loss: 0.1126 - val_accuracy: 0.9583\n",
      "Epoch 170/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0654 - accuracy: 0.9758 - val_loss: 0.1046 - val_accuracy: 0.9630\n",
      "Epoch 171/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0759 - accuracy: 0.9769 - val_loss: 0.0832 - val_accuracy: 0.9722\n",
      "Epoch 172/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0799 - accuracy: 0.9746 - val_loss: 0.4334 - val_accuracy: 0.8889\n",
      "Epoch 173/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.1150 - accuracy: 0.9642 - val_loss: 0.0881 - val_accuracy: 0.9583\n",
      "Epoch 174/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0663 - accuracy: 0.9769 - val_loss: 0.0944 - val_accuracy: 0.9630\n",
      "Epoch 175/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0519 - accuracy: 0.9838 - val_loss: 0.1073 - val_accuracy: 0.9630\n",
      "Epoch 176/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0506 - accuracy: 0.9850 - val_loss: 0.1194 - val_accuracy: 0.9537\n",
      "Epoch 177/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0806 - accuracy: 0.9758 - val_loss: 0.1370 - val_accuracy: 0.9630\n",
      "Epoch 178/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0649 - accuracy: 0.9769 - val_loss: 0.1136 - val_accuracy: 0.9630\n",
      "Epoch 179/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0556 - accuracy: 0.9804 - val_loss: 0.0997 - val_accuracy: 0.9630\n",
      "Epoch 180/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0594 - accuracy: 0.9804 - val_loss: 0.1131 - val_accuracy: 0.9583\n",
      "Epoch 181/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0757 - accuracy: 0.9758 - val_loss: 0.1113 - val_accuracy: 0.9583\n",
      "Epoch 182/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0664 - accuracy: 0.9769 - val_loss: 0.1142 - val_accuracy: 0.9583\n",
      "Epoch 183/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0462 - accuracy: 0.9827 - val_loss: 0.2407 - val_accuracy: 0.9444\n",
      "Epoch 184/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0648 - accuracy: 0.9781 - val_loss: 0.1152 - val_accuracy: 0.9583\n",
      "Epoch 185/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0834 - accuracy: 0.9723 - val_loss: 0.1271 - val_accuracy: 0.9583\n",
      "Epoch 186/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0658 - accuracy: 0.9734 - val_loss: 0.1113 - val_accuracy: 0.9583\n",
      "Epoch 187/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0680 - accuracy: 0.9815 - val_loss: 0.1310 - val_accuracy: 0.9676\n",
      "Epoch 188/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0675 - accuracy: 0.9746 - val_loss: 0.1079 - val_accuracy: 0.9630\n",
      "Epoch 189/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0613 - accuracy: 0.9792 - val_loss: 0.1046 - val_accuracy: 0.9583\n",
      "Epoch 190/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0521 - accuracy: 0.9850 - val_loss: 0.1313 - val_accuracy: 0.9630\n",
      "Epoch 191/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0593 - accuracy: 0.9769 - val_loss: 0.1287 - val_accuracy: 0.9583\n",
      "Epoch 192/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0673 - accuracy: 0.9792 - val_loss: 0.1096 - val_accuracy: 0.9630\n",
      "Epoch 193/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0611 - accuracy: 0.9827 - val_loss: 0.1141 - val_accuracy: 0.9583\n",
      "Epoch 194/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0592 - accuracy: 0.9815 - val_loss: 0.1087 - val_accuracy: 0.9583\n",
      "Epoch 195/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0720 - accuracy: 0.9758 - val_loss: 0.1571 - val_accuracy: 0.9537\n",
      "Epoch 196/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0557 - accuracy: 0.9850 - val_loss: 0.1101 - val_accuracy: 0.9537\n",
      "Epoch 197/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.1265 - val_accuracy: 0.9630\n",
      "Epoch 198/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0554 - accuracy: 0.9838 - val_loss: 0.1186 - val_accuracy: 0.9630\n",
      "Epoch 199/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0542 - accuracy: 0.9746 - val_loss: 0.1495 - val_accuracy: 0.9537\n",
      "Epoch 200/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0817 - accuracy: 0.9734 - val_loss: 0.1229 - val_accuracy: 0.9583\n",
      "Epoch 201/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0523 - accuracy: 0.9827 - val_loss: 0.1050 - val_accuracy: 0.9583\n",
      "Epoch 202/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0632 - accuracy: 0.9815 - val_loss: 0.1813 - val_accuracy: 0.9491\n",
      "Epoch 203/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.1226 - val_accuracy: 0.9630\n",
      "Epoch 204/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0473 - accuracy: 0.9861 - val_loss: 0.1186 - val_accuracy: 0.9583\n",
      "Epoch 205/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0579 - accuracy: 0.9792 - val_loss: 0.1318 - val_accuracy: 0.9583\n",
      "Epoch 206/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0469 - accuracy: 0.9873 - val_loss: 0.1072 - val_accuracy: 0.9537\n",
      "Epoch 207/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0596 - accuracy: 0.9838 - val_loss: 0.0923 - val_accuracy: 0.9583\n",
      "Epoch 208/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.1931 - val_accuracy: 0.9444\n",
      "Epoch 209/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0711 - accuracy: 0.9769 - val_loss: 0.1144 - val_accuracy: 0.9630\n",
      "Epoch 210/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0552 - accuracy: 0.9804 - val_loss: 0.1468 - val_accuracy: 0.9537\n",
      "Epoch 211/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0480 - accuracy: 0.9861 - val_loss: 0.1065 - val_accuracy: 0.9583\n",
      "Epoch 212/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0549 - accuracy: 0.9861 - val_loss: 0.1150 - val_accuracy: 0.9630\n",
      "Epoch 213/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0547 - accuracy: 0.9838 - val_loss: 0.1262 - val_accuracy: 0.9583\n",
      "Epoch 214/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0736 - accuracy: 0.9746 - val_loss: 0.1178 - val_accuracy: 0.9630\n",
      "Epoch 215/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0579 - accuracy: 0.9769 - val_loss: 0.0997 - val_accuracy: 0.9583\n",
      "Epoch 216/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0640 - accuracy: 0.9769 - val_loss: 0.1115 - val_accuracy: 0.9583\n",
      "Epoch 217/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0437 - accuracy: 0.9838 - val_loss: 0.0994 - val_accuracy: 0.9630\n",
      "Epoch 218/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0366 - accuracy: 0.9908 - val_loss: 0.1402 - val_accuracy: 0.9630\n",
      "Epoch 219/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0411 - accuracy: 0.9850 - val_loss: 0.1117 - val_accuracy: 0.9583\n",
      "Epoch 220/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 0.1069 - val_accuracy: 0.9676\n",
      "Epoch 221/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0365 - accuracy: 0.9896 - val_loss: 0.1247 - val_accuracy: 0.9583\n",
      "Epoch 222/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0614 - accuracy: 0.9827 - val_loss: 0.1035 - val_accuracy: 0.9676\n",
      "Epoch 223/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0370 - accuracy: 0.9908 - val_loss: 0.1479 - val_accuracy: 0.9583\n",
      "Epoch 224/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0501 - accuracy: 0.9861 - val_loss: 0.1353 - val_accuracy: 0.9583\n",
      "Epoch 225/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0445 - accuracy: 0.9896 - val_loss: 0.1979 - val_accuracy: 0.9444\n",
      "Epoch 226/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0474 - accuracy: 0.9781 - val_loss: 0.1170 - val_accuracy: 0.9583\n",
      "Epoch 227/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0362 - accuracy: 0.9873 - val_loss: 0.1369 - val_accuracy: 0.9676\n",
      "Epoch 228/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0426 - accuracy: 0.9861 - val_loss: 0.1175 - val_accuracy: 0.9630\n",
      "Epoch 229/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 0.1149 - val_accuracy: 0.9537\n",
      "Epoch 230/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0541 - accuracy: 0.9861 - val_loss: 0.1181 - val_accuracy: 0.9630\n",
      "Epoch 231/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0504 - accuracy: 0.9850 - val_loss: 0.1445 - val_accuracy: 0.9583\n",
      "Epoch 232/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0397 - accuracy: 0.9896 - val_loss: 0.1352 - val_accuracy: 0.9583\n",
      "Epoch 233/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0400 - accuracy: 0.9919 - val_loss: 0.1268 - val_accuracy: 0.9630\n",
      "Epoch 234/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0446 - accuracy: 0.9838 - val_loss: 0.1282 - val_accuracy: 0.9583\n",
      "Epoch 235/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0465 - accuracy: 0.9838 - val_loss: 0.1215 - val_accuracy: 0.9630\n",
      "Epoch 236/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0390 - accuracy: 0.9873 - val_loss: 0.1567 - val_accuracy: 0.9630\n",
      "Epoch 237/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0703 - accuracy: 0.9723 - val_loss: 0.1401 - val_accuracy: 0.9537\n",
      "Epoch 238/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 0.1232 - val_accuracy: 0.9630\n",
      "Epoch 239/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0399 - accuracy: 0.9885 - val_loss: 0.1415 - val_accuracy: 0.9630\n",
      "Epoch 240/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0521 - accuracy: 0.9838 - val_loss: 0.1146 - val_accuracy: 0.9583\n",
      "Epoch 241/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0394 - accuracy: 0.9873 - val_loss: 0.1133 - val_accuracy: 0.9630\n",
      "Epoch 242/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.1457 - val_accuracy: 0.9583\n",
      "Epoch 243/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0448 - accuracy: 0.9885 - val_loss: 0.1236 - val_accuracy: 0.9630\n",
      "Epoch 244/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.1373 - val_accuracy: 0.9491\n",
      "Epoch 245/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0420 - accuracy: 0.9873 - val_loss: 0.1365 - val_accuracy: 0.9583\n",
      "Epoch 246/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0558 - accuracy: 0.9781 - val_loss: 0.1298 - val_accuracy: 0.9537\n",
      "Epoch 247/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0382 - accuracy: 0.9861 - val_loss: 0.1213 - val_accuracy: 0.9583\n",
      "Epoch 248/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.1621 - val_accuracy: 0.9583\n",
      "Epoch 249/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0405 - accuracy: 0.9850 - val_loss: 0.1339 - val_accuracy: 0.9583\n",
      "Epoch 250/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0275 - accuracy: 0.9908 - val_loss: 0.1719 - val_accuracy: 0.9583\n",
      "Epoch 251/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0608 - accuracy: 0.9792 - val_loss: 0.1347 - val_accuracy: 0.9537\n",
      "Epoch 252/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0447 - accuracy: 0.9850 - val_loss: 0.1298 - val_accuracy: 0.9630\n",
      "Epoch 253/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0411 - accuracy: 0.9908 - val_loss: 0.1265 - val_accuracy: 0.9630\n",
      "Epoch 254/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0373 - accuracy: 0.9896 - val_loss: 0.1478 - val_accuracy: 0.9583\n",
      "Epoch 255/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0352 - accuracy: 0.9885 - val_loss: 0.1334 - val_accuracy: 0.9583\n",
      "Epoch 256/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0845 - accuracy: 0.9677 - val_loss: 0.1823 - val_accuracy: 0.9491\n",
      "Epoch 257/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.1475 - val_accuracy: 0.9583\n",
      "Epoch 258/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0625 - accuracy: 0.9827 - val_loss: 0.1301 - val_accuracy: 0.9583\n",
      "Epoch 259/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0378 - accuracy: 0.9896 - val_loss: 0.1234 - val_accuracy: 0.9630\n",
      "Epoch 260/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0391 - accuracy: 0.9850 - val_loss: 0.1097 - val_accuracy: 0.9583\n",
      "Epoch 261/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0432 - accuracy: 0.9885 - val_loss: 0.0976 - val_accuracy: 0.9583\n",
      "Epoch 262/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0463 - accuracy: 0.9850 - val_loss: 0.1152 - val_accuracy: 0.9676\n",
      "Epoch 263/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0446 - accuracy: 0.9815 - val_loss: 0.1107 - val_accuracy: 0.9630\n",
      "Epoch 264/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0483 - accuracy: 0.9850 - val_loss: 0.1575 - val_accuracy: 0.9583\n",
      "Epoch 265/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0833 - accuracy: 0.9734 - val_loss: 0.1370 - val_accuracy: 0.9583\n",
      "Epoch 266/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0445 - accuracy: 0.9873 - val_loss: 0.1220 - val_accuracy: 0.9583\n",
      "Epoch 267/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 0.1268 - val_accuracy: 0.9630\n",
      "Epoch 268/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0420 - accuracy: 0.9838 - val_loss: 0.1319 - val_accuracy: 0.9583\n",
      "Epoch 269/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0401 - accuracy: 0.9919 - val_loss: 0.1278 - val_accuracy: 0.9630\n",
      "Epoch 270/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.1288 - val_accuracy: 0.9630\n",
      "Epoch 271/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0315 - accuracy: 0.9942 - val_loss: 0.1391 - val_accuracy: 0.9630\n",
      "Epoch 272/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0315 - accuracy: 0.9919 - val_loss: 0.1495 - val_accuracy: 0.9630\n",
      "Epoch 273/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.1486 - val_accuracy: 0.9676\n",
      "Epoch 274/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.1433 - val_accuracy: 0.9537\n",
      "Epoch 275/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0313 - accuracy: 0.9919 - val_loss: 0.1429 - val_accuracy: 0.9630\n",
      "Epoch 276/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.1592 - val_accuracy: 0.9583\n",
      "Epoch 277/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0402 - accuracy: 0.9827 - val_loss: 0.1330 - val_accuracy: 0.9583\n",
      "Epoch 278/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0428 - accuracy: 0.9873 - val_loss: 0.1157 - val_accuracy: 0.9583\n",
      "Epoch 279/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0208 - accuracy: 0.9965 - val_loss: 0.1250 - val_accuracy: 0.9630\n",
      "Epoch 280/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0497 - accuracy: 0.9850 - val_loss: 0.1399 - val_accuracy: 0.9583\n",
      "Epoch 281/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0240 - accuracy: 0.9931 - val_loss: 0.1442 - val_accuracy: 0.9583\n",
      "Epoch 282/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0315 - accuracy: 0.9931 - val_loss: 0.1503 - val_accuracy: 0.9630\n",
      "Epoch 283/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.1473 - val_accuracy: 0.9630\n",
      "Epoch 284/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.1542 - val_accuracy: 0.9537\n",
      "Epoch 285/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0232 - accuracy: 0.9954 - val_loss: 0.1565 - val_accuracy: 0.9583\n",
      "Epoch 286/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0385 - accuracy: 0.9850 - val_loss: 0.1389 - val_accuracy: 0.9537\n",
      "Epoch 287/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0349 - accuracy: 0.9885 - val_loss: 0.1448 - val_accuracy: 0.9583\n",
      "Epoch 288/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0280 - accuracy: 0.9931 - val_loss: 0.1646 - val_accuracy: 0.9630\n",
      "Epoch 289/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.1619 - val_accuracy: 0.9583\n",
      "Epoch 290/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0331 - accuracy: 0.9942 - val_loss: 0.1361 - val_accuracy: 0.9630\n",
      "Epoch 291/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0338 - accuracy: 0.9885 - val_loss: 0.1239 - val_accuracy: 0.9722\n",
      "Epoch 292/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.1482 - val_accuracy: 0.9583\n",
      "Epoch 293/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 0.1657 - val_accuracy: 0.9583\n",
      "Epoch 294/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 0.1618 - val_accuracy: 0.9630\n",
      "Epoch 295/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0243 - accuracy: 0.9942 - val_loss: 0.1574 - val_accuracy: 0.9537\n",
      "Epoch 296/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.1612 - val_accuracy: 0.9630\n",
      "Epoch 297/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0803 - accuracy: 0.9746 - val_loss: 0.0934 - val_accuracy: 0.9630\n",
      "Epoch 298/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0304 - accuracy: 0.9908 - val_loss: 0.1300 - val_accuracy: 0.9630\n",
      "Epoch 299/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0451 - accuracy: 0.9850 - val_loss: 0.1396 - val_accuracy: 0.9583\n",
      "Epoch 300/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.1443 - val_accuracy: 0.9583\n",
      "Epoch 301/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0349 - accuracy: 0.9838 - val_loss: 0.1378 - val_accuracy: 0.9491\n",
      "Epoch 302/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0295 - accuracy: 0.9919 - val_loss: 0.1374 - val_accuracy: 0.9630\n",
      "Epoch 303/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0235 - accuracy: 0.9942 - val_loss: 0.1867 - val_accuracy: 0.9630\n",
      "Epoch 304/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0204 - accuracy: 0.9919 - val_loss: 0.1768 - val_accuracy: 0.9537\n",
      "Epoch 305/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.1575 - val_accuracy: 0.9537\n",
      "Epoch 306/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.1883 - val_accuracy: 0.9491\n",
      "Epoch 307/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.1725 - val_accuracy: 0.9583\n",
      "Epoch 308/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0331 - accuracy: 0.9919 - val_loss: 0.1794 - val_accuracy: 0.9630\n",
      "Epoch 309/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 0.1677 - val_accuracy: 0.9676\n",
      "Epoch 310/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0439 - accuracy: 0.9827 - val_loss: 0.1659 - val_accuracy: 0.9583\n",
      "Epoch 311/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0304 - accuracy: 0.9919 - val_loss: 0.1551 - val_accuracy: 0.9583\n",
      "Epoch 312/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.1700 - val_accuracy: 0.9630\n",
      "Epoch 313/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 0.1756 - val_accuracy: 0.9583\n",
      "Epoch 314/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.1382 - val_accuracy: 0.9583\n",
      "Epoch 315/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.1802 - val_accuracy: 0.9537\n",
      "Epoch 316/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0288 - accuracy: 0.9931 - val_loss: 0.1871 - val_accuracy: 0.9537\n",
      "Epoch 317/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.1777 - val_accuracy: 0.9630\n",
      "Epoch 318/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.1816 - val_accuracy: 0.9630\n",
      "Epoch 319/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0298 - accuracy: 0.9885 - val_loss: 0.1480 - val_accuracy: 0.9630\n",
      "Epoch 320/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0326 - accuracy: 0.9919 - val_loss: 0.1528 - val_accuracy: 0.9583\n",
      "Epoch 321/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0250 - accuracy: 0.9908 - val_loss: 0.1605 - val_accuracy: 0.9583\n",
      "Epoch 322/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0194 - accuracy: 0.9977 - val_loss: 0.1790 - val_accuracy: 0.9676\n",
      "Epoch 323/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 0.1905 - val_accuracy: 0.9537\n",
      "Epoch 324/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.1916 - val_accuracy: 0.9537\n",
      "Epoch 325/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.1493 - val_accuracy: 0.9537\n",
      "Epoch 326/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.1673 - val_accuracy: 0.9676\n",
      "Epoch 327/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.1593 - val_accuracy: 0.9676\n",
      "Epoch 328/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0220 - accuracy: 0.9942 - val_loss: 0.1743 - val_accuracy: 0.9583\n",
      "Epoch 329/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0178 - accuracy: 0.9965 - val_loss: 0.1305 - val_accuracy: 0.9630\n",
      "Epoch 330/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.1859 - accuracy: 0.9607 - val_loss: 0.1215 - val_accuracy: 0.9583\n",
      "Epoch 331/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0320 - accuracy: 0.9931 - val_loss: 0.1220 - val_accuracy: 0.9583\n",
      "Epoch 332/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0274 - accuracy: 0.9908 - val_loss: 0.1459 - val_accuracy: 0.9583\n",
      "Epoch 333/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0300 - accuracy: 0.9885 - val_loss: 0.1349 - val_accuracy: 0.9676\n",
      "Epoch 334/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0281 - accuracy: 0.9919 - val_loss: 0.1743 - val_accuracy: 0.9491\n",
      "Epoch 335/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0254 - accuracy: 0.9931 - val_loss: 0.1538 - val_accuracy: 0.9676\n",
      "Epoch 336/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.1398 - val_accuracy: 0.9583\n",
      "Epoch 337/1000\n",
      "28/28 [==============================] - 1s 30ms/step - loss: 0.0178 - accuracy: 0.9931 - val_loss: 0.1509 - val_accuracy: 0.9676\n",
      "Epoch 338/1000\n",
      "28/28 [==============================] - 1s 31ms/step - loss: 0.0590 - accuracy: 0.9838 - val_loss: 0.1658 - val_accuracy: 0.9583\n",
      "Epoch 339/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.1669 - val_accuracy: 0.9630\n",
      "Epoch 340/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.1708 - val_accuracy: 0.9676\n",
      "Epoch 341/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0287 - accuracy: 0.9919 - val_loss: 0.1677 - val_accuracy: 0.9583\n",
      "Epoch 342/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0286 - accuracy: 0.9896 - val_loss: 0.1617 - val_accuracy: 0.9630\n",
      "Epoch 343/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.1662 - val_accuracy: 0.9537\n",
      "Epoch 344/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.1814 - val_accuracy: 0.9583\n",
      "Epoch 345/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0261 - accuracy: 0.9931 - val_loss: 0.1813 - val_accuracy: 0.9583\n",
      "Epoch 346/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0246 - accuracy: 0.9896 - val_loss: 0.1796 - val_accuracy: 0.9583\n",
      "Epoch 347/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0340 - accuracy: 0.9873 - val_loss: 0.1808 - val_accuracy: 0.9583\n",
      "Epoch 348/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.1766 - val_accuracy: 0.9676\n",
      "Epoch 349/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0228 - accuracy: 0.9965 - val_loss: 0.1708 - val_accuracy: 0.9583\n",
      "Epoch 350/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.1902 - val_accuracy: 0.9537\n",
      "Epoch 351/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.1479 - val_accuracy: 0.9630\n",
      "Epoch 352/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0238 - accuracy: 0.9954 - val_loss: 0.1629 - val_accuracy: 0.9676\n",
      "Epoch 353/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0220 - accuracy: 0.9954 - val_loss: 0.1839 - val_accuracy: 0.9630\n",
      "Epoch 354/1000\n",
      "28/28 [==============================] - 1s 32ms/step - loss: 0.0201 - accuracy: 0.9919 - val_loss: 0.1794 - val_accuracy: 0.9676\n",
      "Epoch 355/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0585 - accuracy: 0.9850 - val_loss: 0.1735 - val_accuracy: 0.9630\n",
      "Epoch 356/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0171 - accuracy: 0.9954 - val_loss: 0.2054 - val_accuracy: 0.9676\n",
      "Epoch 357/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0174 - accuracy: 0.9931 - val_loss: 0.1629 - val_accuracy: 0.9583\n",
      "Epoch 358/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1805 - val_accuracy: 0.9491\n",
      "Epoch 359/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0198 - accuracy: 0.9919 - val_loss: 0.1946 - val_accuracy: 0.9676\n",
      "Epoch 360/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.1892 - val_accuracy: 0.9630\n",
      "Epoch 361/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.1799 - val_accuracy: 0.9537\n",
      "Epoch 362/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.1842 - val_accuracy: 0.9676\n",
      "Epoch 363/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0142 - accuracy: 0.9977 - val_loss: 0.1748 - val_accuracy: 0.9676\n",
      "Epoch 364/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0190 - accuracy: 0.9965 - val_loss: 0.2493 - val_accuracy: 0.9491\n",
      "Epoch 365/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0351 - accuracy: 0.9838 - val_loss: 0.1410 - val_accuracy: 0.9676\n",
      "Epoch 366/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 1.1939 - val_accuracy: 0.7176\n",
      "Epoch 367/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1940 - accuracy: 0.9492 - val_loss: 0.0956 - val_accuracy: 0.9630\n",
      "Epoch 368/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 0.1017 - val_accuracy: 0.9583\n",
      "Epoch 369/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 0.1263 - val_accuracy: 0.9630\n",
      "Epoch 370/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.1437 - val_accuracy: 0.9630\n",
      "Epoch 371/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 0.1551 - val_accuracy: 0.9491\n",
      "Epoch 372/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0209 - accuracy: 0.9942 - val_loss: 0.1391 - val_accuracy: 0.9630\n",
      "Epoch 373/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0264 - accuracy: 0.9896 - val_loss: 0.1651 - val_accuracy: 0.9583\n",
      "Epoch 374/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.1668 - val_accuracy: 0.9583\n",
      "Epoch 375/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.1591 - val_accuracy: 0.9630\n",
      "Epoch 376/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0209 - accuracy: 0.9954 - val_loss: 0.1614 - val_accuracy: 0.9583\n",
      "Epoch 377/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0179 - accuracy: 0.9931 - val_loss: 0.1348 - val_accuracy: 0.9583\n",
      "Epoch 378/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0277 - accuracy: 0.9931 - val_loss: 0.1393 - val_accuracy: 0.9630\n",
      "Epoch 379/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0264 - accuracy: 0.9942 - val_loss: 0.1637 - val_accuracy: 0.9537\n",
      "Epoch 380/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.1586 - val_accuracy: 0.9676\n",
      "Epoch 381/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0228 - accuracy: 0.9931 - val_loss: 0.1750 - val_accuracy: 0.9630\n",
      "Epoch 382/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0341 - accuracy: 0.9885 - val_loss: 0.1360 - val_accuracy: 0.9630\n",
      "Epoch 383/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.1303 - val_accuracy: 0.9630\n",
      "Epoch 384/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0264 - accuracy: 0.9827 - val_loss: 0.1551 - val_accuracy: 0.9491\n",
      "Epoch 385/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.1523 - val_accuracy: 0.9630\n",
      "Epoch 386/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.1677 - val_accuracy: 0.9676\n",
      "Epoch 387/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0215 - accuracy: 0.9919 - val_loss: 0.1339 - val_accuracy: 0.9630\n",
      "Epoch 388/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.1577 - val_accuracy: 0.9676\n",
      "Epoch 389/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.1644 - val_accuracy: 0.9630\n",
      "Epoch 390/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 0.1600 - val_accuracy: 0.9630\n",
      "Epoch 391/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.1627 - val_accuracy: 0.9630\n",
      "Epoch 392/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0121 - accuracy: 0.9965 - val_loss: 0.1496 - val_accuracy: 0.9537\n",
      "Epoch 393/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9630\n",
      "Epoch 394/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0106 - accuracy: 0.9954 - val_loss: 0.1896 - val_accuracy: 0.9630\n",
      "Epoch 395/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0349 - accuracy: 0.9896 - val_loss: 0.1770 - val_accuracy: 0.9630\n",
      "Epoch 396/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.1295 - val_accuracy: 0.9676\n",
      "Epoch 397/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.1504 - val_accuracy: 0.9583\n",
      "Epoch 398/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.1946 - val_accuracy: 0.9676\n",
      "Epoch 399/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.1582 - val_accuracy: 0.9583\n",
      "Epoch 400/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.1668 - val_accuracy: 0.9583\n",
      "Epoch 401/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0086 - accuracy: 0.9965 - val_loss: 0.1782 - val_accuracy: 0.9630\n",
      "Epoch 402/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.2049 - val_accuracy: 0.9583\n",
      "Epoch 403/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0332 - accuracy: 0.9885 - val_loss: 0.1810 - val_accuracy: 0.9630\n",
      "Epoch 404/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0224 - accuracy: 0.9908 - val_loss: 0.2043 - val_accuracy: 0.9630\n",
      "Epoch 405/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0213 - accuracy: 0.9919 - val_loss: 0.1810 - val_accuracy: 0.9537\n",
      "Epoch 406/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0248 - accuracy: 0.9919 - val_loss: 0.1833 - val_accuracy: 0.9630\n",
      "Epoch 407/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0185 - accuracy: 0.9965 - val_loss: 0.1699 - val_accuracy: 0.9583\n",
      "Epoch 408/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0187 - accuracy: 0.9931 - val_loss: 0.1834 - val_accuracy: 0.9630\n",
      "Epoch 409/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.1366 - val_accuracy: 0.9630\n",
      "Epoch 410/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.1762 - val_accuracy: 0.9676\n",
      "Epoch 411/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.1788 - val_accuracy: 0.9676\n",
      "Epoch 412/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.1962 - val_accuracy: 0.9630\n",
      "Epoch 413/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.1696 - val_accuracy: 0.9676\n",
      "Epoch 414/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.1929 - val_accuracy: 0.9676\n",
      "Epoch 415/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.1898 - val_accuracy: 0.9630\n",
      "Epoch 416/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.2089 - val_accuracy: 0.9630\n",
      "Epoch 417/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.1982 - val_accuracy: 0.9630\n",
      "Epoch 418/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.2212 - val_accuracy: 0.9583\n",
      "Epoch 419/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0156 - accuracy: 0.9931 - val_loss: 0.2213 - val_accuracy: 0.9630\n",
      "Epoch 420/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0198 - accuracy: 0.9931 - val_loss: 0.2008 - val_accuracy: 0.9676\n",
      "Epoch 421/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.1740 - val_accuracy: 0.9676\n",
      "Epoch 422/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0100 - accuracy: 0.9942 - val_loss: 0.1975 - val_accuracy: 0.9630\n",
      "Epoch 423/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1879 - val_accuracy: 0.9630\n",
      "Epoch 424/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.2080 - val_accuracy: 0.9630\n",
      "Epoch 425/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.2053 - val_accuracy: 0.9583\n",
      "Epoch 426/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.2143 - val_accuracy: 0.9676\n",
      "Epoch 427/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0280 - accuracy: 0.9919 - val_loss: 0.2793 - val_accuracy: 0.9444\n",
      "Epoch 428/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.1792 - val_accuracy: 0.9583\n",
      "Epoch 429/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.1996 - val_accuracy: 0.9630\n",
      "Epoch 430/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0219 - accuracy: 0.9919 - val_loss: 0.1960 - val_accuracy: 0.9583\n",
      "Epoch 431/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.2013 - val_accuracy: 0.9676\n",
      "Epoch 432/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.2044 - val_accuracy: 0.9630\n",
      "Epoch 433/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.1984 - val_accuracy: 0.9630\n",
      "Epoch 434/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0116 - accuracy: 0.9954 - val_loss: 0.2090 - val_accuracy: 0.9630\n",
      "Epoch 435/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0193 - accuracy: 0.9931 - val_loss: 0.1580 - val_accuracy: 0.9583\n",
      "Epoch 436/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.1938 - val_accuracy: 0.9583\n",
      "Epoch 437/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1904 - val_accuracy: 0.9583\n",
      "Epoch 438/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0219 - accuracy: 0.9919 - val_loss: 0.1983 - val_accuracy: 0.9537\n",
      "Epoch 439/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0271 - accuracy: 0.9931 - val_loss: 0.2711 - val_accuracy: 0.9583\n",
      "Epoch 440/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0178 - accuracy: 0.9919 - val_loss: 0.1725 - val_accuracy: 0.9537\n",
      "Epoch 441/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.1761 - val_accuracy: 0.9630\n",
      "Epoch 442/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.2037 - val_accuracy: 0.9630\n",
      "Epoch 443/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2072 - val_accuracy: 0.9583\n",
      "Epoch 444/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.2177 - val_accuracy: 0.9583\n",
      "Epoch 445/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.2072 - val_accuracy: 0.9537\n",
      "Epoch 446/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0097 - accuracy: 0.9977 - val_loss: 0.1949 - val_accuracy: 0.9583\n",
      "Epoch 447/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.1959 - val_accuracy: 0.9630\n",
      "Epoch 448/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9630\n",
      "Epoch 449/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9676\n",
      "Epoch 450/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.2163 - val_accuracy: 0.9630\n",
      "Epoch 451/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.1938 - val_accuracy: 0.9630\n",
      "Epoch 452/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0137 - accuracy: 0.9931 - val_loss: 0.2258 - val_accuracy: 0.9537\n",
      "Epoch 453/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.3001 - val_accuracy: 0.9583\n",
      "Epoch 454/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.2120 - val_accuracy: 0.9630\n",
      "Epoch 455/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0074 - accuracy: 0.9965 - val_loss: 0.2095 - val_accuracy: 0.9630\n",
      "Epoch 456/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.2080 - val_accuracy: 0.9630\n",
      "Epoch 457/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.2199 - val_accuracy: 0.9537\n",
      "Epoch 458/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.2226 - val_accuracy: 0.9537\n",
      "Epoch 459/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.2239 - val_accuracy: 0.9537\n",
      "Epoch 460/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0274 - accuracy: 0.9861 - val_loss: 0.2148 - val_accuracy: 0.9583\n",
      "Epoch 461/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.2243 - val_accuracy: 0.9583\n",
      "Epoch 462/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.3214 - val_accuracy: 0.9491\n",
      "Epoch 463/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0450 - accuracy: 0.9838 - val_loss: 0.1881 - val_accuracy: 0.9583\n",
      "Epoch 464/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0314 - accuracy: 0.9873 - val_loss: 0.3141 - val_accuracy: 0.9491\n",
      "Epoch 465/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0283 - accuracy: 0.9896 - val_loss: 0.1440 - val_accuracy: 0.9630\n",
      "Epoch 466/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.1705 - val_accuracy: 0.9630\n",
      "Epoch 467/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.2133 - val_accuracy: 0.9537\n",
      "Epoch 468/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0152 - accuracy: 0.9908 - val_loss: 0.2232 - val_accuracy: 0.9491\n",
      "Epoch 469/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.2328 - val_accuracy: 0.9630\n",
      "Epoch 470/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0310 - accuracy: 0.9873 - val_loss: 0.1660 - val_accuracy: 0.9491\n",
      "Epoch 471/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0136 - accuracy: 0.9977 - val_loss: 0.1784 - val_accuracy: 0.9537\n",
      "Epoch 472/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 0.2020 - val_accuracy: 0.9630\n",
      "Epoch 473/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.2011 - val_accuracy: 0.9537\n",
      "Epoch 474/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.2234 - val_accuracy: 0.9583\n",
      "Epoch 475/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0124 - accuracy: 0.9942 - val_loss: 0.2321 - val_accuracy: 0.9537\n",
      "Epoch 476/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9977 - val_loss: 0.2393 - val_accuracy: 0.9537\n",
      "Epoch 477/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0161 - accuracy: 0.9954 - val_loss: 0.2711 - val_accuracy: 0.9630\n",
      "Epoch 478/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.2787 - val_accuracy: 0.9630\n",
      "Epoch 479/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.2791 - val_accuracy: 0.9630\n",
      "Epoch 480/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.2640 - val_accuracy: 0.9630\n",
      "Epoch 481/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.2519 - val_accuracy: 0.9630\n",
      "Epoch 482/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0064 - accuracy: 0.9965 - val_loss: 0.2507 - val_accuracy: 0.9583\n",
      "Epoch 483/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.2588 - val_accuracy: 0.9537\n",
      "Epoch 484/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.2462 - val_accuracy: 0.9537\n",
      "Epoch 485/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.2444 - val_accuracy: 0.9583\n",
      "Epoch 486/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.2604 - val_accuracy: 0.9583\n",
      "Epoch 487/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.2501 - val_accuracy: 0.9630\n",
      "Epoch 488/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.2343 - val_accuracy: 0.9676\n",
      "Epoch 489/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.2726 - val_accuracy: 0.9676\n",
      "Epoch 490/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0508 - accuracy: 0.9792 - val_loss: 0.3780 - val_accuracy: 0.9491\n",
      "Epoch 491/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0361 - accuracy: 0.9873 - val_loss: 0.2407 - val_accuracy: 0.9537\n",
      "Epoch 492/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.2376 - val_accuracy: 0.9537\n",
      "Epoch 493/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.2262 - val_accuracy: 0.9537\n",
      "Epoch 494/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.2059 - val_accuracy: 0.9583\n",
      "Epoch 495/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9537\n",
      "Epoch 496/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.2410 - val_accuracy: 0.9583\n",
      "Epoch 497/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9583\n",
      "Epoch 498/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.2475 - val_accuracy: 0.9676\n",
      "Epoch 499/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0091 - accuracy: 0.9988 - val_loss: 0.2655 - val_accuracy: 0.9537\n",
      "Epoch 500/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.2542 - val_accuracy: 0.9630\n",
      "Epoch 501/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.1841 - val_accuracy: 0.9676\n",
      "Epoch 502/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.2644 - val_accuracy: 0.9676\n",
      "Epoch 503/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.2857 - val_accuracy: 0.9537\n",
      "Epoch 504/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0118 - accuracy: 0.9942 - val_loss: 0.2648 - val_accuracy: 0.9583\n",
      "Epoch 505/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.2850 - val_accuracy: 0.9676\n",
      "Epoch 506/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.2403 - val_accuracy: 0.9583\n",
      "Epoch 507/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0424 - accuracy: 0.9896 - val_loss: 0.2036 - val_accuracy: 0.9630\n",
      "Epoch 508/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0136 - accuracy: 0.9977 - val_loss: 0.2073 - val_accuracy: 0.9630\n",
      "Epoch 509/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0237 - accuracy: 0.9931 - val_loss: 0.1902 - val_accuracy: 0.9583\n",
      "Epoch 510/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.1993 - val_accuracy: 0.9676\n",
      "Epoch 511/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.2059 - val_accuracy: 0.9676\n",
      "Epoch 512/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.2113 - val_accuracy: 0.9630\n",
      "Epoch 513/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9676\n",
      "Epoch 514/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.2198 - val_accuracy: 0.9630\n",
      "Epoch 515/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.2555 - val_accuracy: 0.9676\n",
      "Epoch 516/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.2344 - val_accuracy: 0.9630\n",
      "Epoch 517/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.2445 - val_accuracy: 0.9676\n",
      "Epoch 518/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.2469 - val_accuracy: 0.9630\n",
      "Epoch 519/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.2390 - val_accuracy: 0.9676\n",
      "Epoch 520/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.2823 - val_accuracy: 0.9676\n",
      "Epoch 521/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.2413 - val_accuracy: 0.9676\n",
      "Epoch 522/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.2498 - val_accuracy: 0.9676\n",
      "Epoch 523/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9954 - val_loss: 0.2807 - val_accuracy: 0.9630\n",
      "Epoch 524/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.2579 - val_accuracy: 0.9630\n",
      "Epoch 525/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 0.2524 - val_accuracy: 0.9630\n",
      "Epoch 526/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9965 - val_loss: 0.2789 - val_accuracy: 0.9583\n",
      "Epoch 527/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0164 - accuracy: 0.9931 - val_loss: 0.2305 - val_accuracy: 0.9630\n",
      "Epoch 528/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.2205 - val_accuracy: 0.9676\n",
      "Epoch 529/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.2367 - val_accuracy: 0.9676\n",
      "Epoch 530/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0186 - accuracy: 0.9954 - val_loss: 0.1765 - val_accuracy: 0.9630\n",
      "Epoch 531/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.1996 - val_accuracy: 0.9722\n",
      "Epoch 532/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1989 - val_accuracy: 0.9769\n",
      "Epoch 533/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9722\n",
      "Epoch 534/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.2047 - val_accuracy: 0.9630\n",
      "Epoch 535/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0071 - accuracy: 0.9965 - val_loss: 0.2115 - val_accuracy: 0.9676\n",
      "Epoch 536/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0076 - accuracy: 0.9965 - val_loss: 0.2216 - val_accuracy: 0.9583\n",
      "Epoch 537/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9676\n",
      "Epoch 538/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0055 - accuracy: 0.9977 - val_loss: 0.2195 - val_accuracy: 0.9676\n",
      "Epoch 539/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.2343 - val_accuracy: 0.9676\n",
      "Epoch 540/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.2117 - val_accuracy: 0.9630\n",
      "Epoch 541/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2216 - val_accuracy: 0.9676\n",
      "Epoch 542/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.2401 - val_accuracy: 0.9630\n",
      "Epoch 543/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.2377 - val_accuracy: 0.9630\n",
      "Epoch 544/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.2392 - val_accuracy: 0.9630\n",
      "Epoch 545/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.2711 - val_accuracy: 0.9630\n",
      "Epoch 546/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.2751 - val_accuracy: 0.9583\n",
      "Epoch 547/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9630\n",
      "Epoch 548/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9977 - val_loss: 0.2697 - val_accuracy: 0.9630\n",
      "Epoch 549/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0062 - accuracy: 0.9965 - val_loss: 0.2554 - val_accuracy: 0.9630\n",
      "Epoch 550/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.2529 - val_accuracy: 0.9583\n",
      "Epoch 551/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0152 - accuracy: 0.9977 - val_loss: 0.2299 - val_accuracy: 0.9537\n",
      "Epoch 552/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9583\n",
      "Epoch 553/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0313 - accuracy: 0.9885 - val_loss: 0.2780 - val_accuracy: 0.9583\n",
      "Epoch 554/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.3125 - val_accuracy: 0.9537\n",
      "Epoch 555/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.2753 - val_accuracy: 0.9537\n",
      "Epoch 556/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.2652 - val_accuracy: 0.9583\n",
      "Epoch 557/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.2782 - val_accuracy: 0.9676\n",
      "Epoch 558/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9676\n",
      "Epoch 559/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.3275 - val_accuracy: 0.9676\n",
      "Epoch 560/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.2669 - val_accuracy: 0.9630\n",
      "Epoch 561/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.2759 - val_accuracy: 0.9630\n",
      "Epoch 562/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.2753 - val_accuracy: 0.9583\n",
      "Epoch 563/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.3084 - val_accuracy: 0.9676\n",
      "Epoch 564/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.2745 - val_accuracy: 0.9583\n",
      "Epoch 565/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.2688 - val_accuracy: 0.9583\n",
      "Epoch 566/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0052 - accuracy: 0.9977 - val_loss: 0.2869 - val_accuracy: 0.9491\n",
      "Epoch 567/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.2581 - val_accuracy: 0.9630\n",
      "Epoch 568/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 0.2698 - val_accuracy: 0.9630\n",
      "Epoch 569/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.2765 - val_accuracy: 0.9630\n",
      "Epoch 570/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0168 - accuracy: 0.9965 - val_loss: 0.2759 - val_accuracy: 0.9630\n",
      "Epoch 571/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0054 - accuracy: 0.9977 - val_loss: 0.2887 - val_accuracy: 0.9630\n",
      "Epoch 572/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.2462 - val_accuracy: 0.9583\n",
      "Epoch 573/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.2670 - val_accuracy: 0.9583\n",
      "Epoch 574/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.2977 - val_accuracy: 0.9583\n",
      "Epoch 575/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 0.2703 - val_accuracy: 0.9630\n",
      "Epoch 576/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.2815 - val_accuracy: 0.9630\n",
      "Epoch 577/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0099 - accuracy: 0.9954 - val_loss: 0.2954 - val_accuracy: 0.9630\n",
      "Epoch 578/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.2550 - val_accuracy: 0.9630\n",
      "Epoch 579/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0295 - accuracy: 0.9942 - val_loss: 0.2850 - val_accuracy: 0.9676\n",
      "Epoch 580/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9965 - val_loss: 0.2414 - val_accuracy: 0.9630\n",
      "Epoch 581/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.2800 - val_accuracy: 0.9537\n",
      "Epoch 582/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.2804 - val_accuracy: 0.9630\n",
      "Epoch 583/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.3100 - val_accuracy: 0.9583\n",
      "Epoch 584/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3234 - val_accuracy: 0.9630\n",
      "Epoch 585/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3035 - val_accuracy: 0.9630\n",
      "Epoch 586/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.2913 - val_accuracy: 0.9583\n",
      "Epoch 587/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.2715 - val_accuracy: 0.9583\n",
      "Epoch 588/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2892 - val_accuracy: 0.9630\n",
      "Epoch 589/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.2782 - val_accuracy: 0.9630\n",
      "Epoch 590/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 0.3316 - val_accuracy: 0.9630\n",
      "Epoch 591/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 0.3474 - val_accuracy: 0.9537\n",
      "Epoch 592/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.2849 - val_accuracy: 0.9583\n",
      "Epoch 593/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3107 - val_accuracy: 0.9583\n",
      "Epoch 594/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 0.9630\n",
      "Epoch 595/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0195 - accuracy: 0.9954 - val_loss: 0.2827 - val_accuracy: 0.9583\n",
      "Epoch 596/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0073 - accuracy: 0.9954 - val_loss: 0.2801 - val_accuracy: 0.9630\n",
      "Epoch 597/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9965 - val_loss: 0.3249 - val_accuracy: 0.9630\n",
      "Epoch 598/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.2965 - val_accuracy: 0.9630\n",
      "Epoch 599/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.2869 - val_accuracy: 0.9630\n",
      "Epoch 600/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9630\n",
      "Epoch 601/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0108 - accuracy: 0.9942 - val_loss: 0.2386 - val_accuracy: 0.9722\n",
      "Epoch 602/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.2411 - val_accuracy: 0.9676\n",
      "Epoch 603/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.2537 - val_accuracy: 0.9676\n",
      "Epoch 604/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.2867 - val_accuracy: 0.9583\n",
      "Epoch 605/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.2370 - val_accuracy: 0.9630\n",
      "Epoch 606/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9676\n",
      "Epoch 607/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9676\n",
      "Epoch 608/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 0.2305 - val_accuracy: 0.9676\n",
      "Epoch 609/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.2320 - val_accuracy: 0.9630\n",
      "Epoch 610/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.2339 - val_accuracy: 0.9583\n",
      "Epoch 611/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.2462 - val_accuracy: 0.9676\n",
      "Epoch 612/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0049 - accuracy: 0.9977 - val_loss: 0.2413 - val_accuracy: 0.9630\n",
      "Epoch 613/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.2401 - val_accuracy: 0.9676\n",
      "Epoch 614/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9676\n",
      "Epoch 615/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9676\n",
      "Epoch 616/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.2437 - val_accuracy: 0.9583\n",
      "Epoch 617/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9583\n",
      "Epoch 618/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.2409 - val_accuracy: 0.9630\n",
      "Epoch 619/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.9630\n",
      "Epoch 620/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.2471 - val_accuracy: 0.9630\n",
      "Epoch 621/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.2669 - val_accuracy: 0.9676\n",
      "Epoch 622/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0159 - accuracy: 0.9965 - val_loss: 0.2546 - val_accuracy: 0.9630\n",
      "Epoch 623/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0127 - accuracy: 0.9942 - val_loss: 0.2701 - val_accuracy: 0.9630\n",
      "Epoch 624/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9630\n",
      "Epoch 625/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.2727 - val_accuracy: 0.9630\n",
      "Epoch 626/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.2728 - val_accuracy: 0.9630\n",
      "Epoch 627/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9630\n",
      "Epoch 628/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 0.9676\n",
      "Epoch 629/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0113 - accuracy: 0.9954 - val_loss: 0.2702 - val_accuracy: 0.9583\n",
      "Epoch 630/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9965 - val_loss: 0.3412 - val_accuracy: 0.9676\n",
      "Epoch 631/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.3378 - val_accuracy: 0.9676\n",
      "Epoch 632/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0044 - accuracy: 0.9977 - val_loss: 0.3199 - val_accuracy: 0.9630\n",
      "Epoch 633/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0384 - accuracy: 0.9908 - val_loss: 0.1951 - val_accuracy: 0.9583\n",
      "Epoch 634/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0187 - accuracy: 0.9919 - val_loss: 0.2687 - val_accuracy: 0.9676\n",
      "Epoch 635/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9965 - val_loss: 0.2259 - val_accuracy: 0.9676\n",
      "Epoch 636/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.2341 - val_accuracy: 0.9630\n",
      "Epoch 637/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.2778 - val_accuracy: 0.9676\n",
      "Epoch 638/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9676\n",
      "Epoch 639/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.2736 - val_accuracy: 0.9676\n",
      "Epoch 640/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.2618 - val_accuracy: 0.9676\n",
      "Epoch 641/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.2908 - val_accuracy: 0.9583\n",
      "Epoch 642/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0083 - accuracy: 0.9954 - val_loss: 0.3121 - val_accuracy: 0.9676\n",
      "Epoch 643/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.3037 - val_accuracy: 0.9676\n",
      "Epoch 644/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9676\n",
      "Epoch 645/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2955 - val_accuracy: 0.9676\n",
      "Epoch 646/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 0.9977 - val_loss: 0.3118 - val_accuracy: 0.9676\n",
      "Epoch 647/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.3050 - val_accuracy: 0.9676\n",
      "Epoch 648/1000\n",
      "28/28 [==============================] - 1s 40ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3143 - val_accuracy: 0.9676\n",
      "Epoch 649/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.2819 - val_accuracy: 0.9676\n",
      "Epoch 650/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.3064 - val_accuracy: 0.9583\n",
      "Epoch 651/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.3090 - val_accuracy: 0.9583\n",
      "Epoch 652/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9630\n",
      "Epoch 653/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0056 - accuracy: 0.9965 - val_loss: 0.3233 - val_accuracy: 0.9630\n",
      "Epoch 654/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9630\n",
      "Epoch 655/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.9630\n",
      "Epoch 656/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9583\n",
      "Epoch 657/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3003 - val_accuracy: 0.9676\n",
      "Epoch 658/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0066 - accuracy: 0.9965 - val_loss: 0.2711 - val_accuracy: 0.9630\n",
      "Epoch 659/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.2960 - val_accuracy: 0.9630\n",
      "Epoch 660/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 0.3075 - val_accuracy: 0.9676\n",
      "Epoch 661/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.2853 - val_accuracy: 0.9583\n",
      "Epoch 662/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3031 - val_accuracy: 0.9583\n",
      "Epoch 663/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9630\n",
      "Epoch 664/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.9630\n",
      "Epoch 665/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9676\n",
      "Epoch 666/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.3154 - val_accuracy: 0.9630\n",
      "Epoch 667/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.3121 - val_accuracy: 0.9676\n",
      "Epoch 668/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0791 - accuracy: 0.9746 - val_loss: 0.1916 - val_accuracy: 0.9583\n",
      "Epoch 669/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.2246 - val_accuracy: 0.9630\n",
      "Epoch 670/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0272 - accuracy: 0.9931 - val_loss: 0.2336 - val_accuracy: 0.9630\n",
      "Epoch 671/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.2244 - val_accuracy: 0.9630\n",
      "Epoch 672/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0062 - accuracy: 0.9965 - val_loss: 0.2192 - val_accuracy: 0.9676\n",
      "Epoch 673/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.2351 - val_accuracy: 0.9676\n",
      "Epoch 674/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 0.2555 - val_accuracy: 0.9676\n",
      "Epoch 675/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0093 - accuracy: 0.9954 - val_loss: 0.2587 - val_accuracy: 0.9583\n",
      "Epoch 676/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.2987 - val_accuracy: 0.9630\n",
      "Epoch 677/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.2192 - val_accuracy: 0.9630\n",
      "Epoch 678/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9630\n",
      "Epoch 679/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9630\n",
      "Epoch 680/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0083 - accuracy: 0.9942 - val_loss: 0.2458 - val_accuracy: 0.9722\n",
      "Epoch 681/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.2500 - val_accuracy: 0.9676\n",
      "Epoch 682/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9676\n",
      "Epoch 683/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9676\n",
      "Epoch 684/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.2802 - val_accuracy: 0.9676\n",
      "Epoch 685/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.2769 - val_accuracy: 0.9676\n",
      "Epoch 686/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9630\n",
      "Epoch 687/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9630\n",
      "Epoch 688/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9630\n",
      "Epoch 689/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2927 - val_accuracy: 0.9676\n",
      "Epoch 690/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.2911 - val_accuracy: 0.9722\n",
      "Epoch 691/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.2687 - val_accuracy: 0.9676\n",
      "Epoch 692/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.3064 - val_accuracy: 0.9583\n",
      "Epoch 693/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0171 - accuracy: 0.9977 - val_loss: 0.2589 - val_accuracy: 0.9676\n",
      "Epoch 694/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.2619 - val_accuracy: 0.9676\n",
      "Epoch 695/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 0.9977 - val_loss: 0.2603 - val_accuracy: 0.9630\n",
      "Epoch 696/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9676\n",
      "Epoch 697/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9630\n",
      "Epoch 698/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.2716 - val_accuracy: 0.9630\n",
      "Epoch 699/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 0.2822 - val_accuracy: 0.9676\n",
      "Epoch 700/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.2693 - val_accuracy: 0.9676\n",
      "Epoch 701/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 0.9676\n",
      "Epoch 702/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9676\n",
      "Epoch 703/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9630\n",
      "Epoch 704/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9676\n",
      "Epoch 705/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.3070 - val_accuracy: 0.9676\n",
      "Epoch 706/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9676\n",
      "Epoch 707/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.0642 - accuracy: 0.8718 - val_loss: 0.5094 - val_accuracy: 0.7731\n",
      "Epoch 708/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.3462 - accuracy: 0.8661 - val_loss: 0.2335 - val_accuracy: 0.9120\n",
      "Epoch 709/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1759 - accuracy: 0.9319 - val_loss: 0.1468 - val_accuracy: 0.9398\n",
      "Epoch 710/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1475 - accuracy: 0.9503 - val_loss: 0.1326 - val_accuracy: 0.9398\n",
      "Epoch 711/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1019 - accuracy: 0.9723 - val_loss: 0.1746 - val_accuracy: 0.9352\n",
      "Epoch 712/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.1264 - accuracy: 0.9561 - val_loss: 0.1610 - val_accuracy: 0.9444\n",
      "Epoch 713/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0856 - accuracy: 0.9700 - val_loss: 0.1547 - val_accuracy: 0.9444\n",
      "Epoch 714/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0839 - accuracy: 0.9734 - val_loss: 0.1487 - val_accuracy: 0.9444\n",
      "Epoch 715/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0884 - accuracy: 0.9688 - val_loss: 0.1437 - val_accuracy: 0.9398\n",
      "Epoch 716/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.1015 - accuracy: 0.9665 - val_loss: 0.1454 - val_accuracy: 0.9398\n",
      "Epoch 717/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0873 - accuracy: 0.9804 - val_loss: 0.1174 - val_accuracy: 0.9537\n",
      "Epoch 718/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0876 - accuracy: 0.9677 - val_loss: 0.1504 - val_accuracy: 0.9352\n",
      "Epoch 719/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0634 - accuracy: 0.9804 - val_loss: 0.1494 - val_accuracy: 0.9491\n",
      "Epoch 720/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0791 - accuracy: 0.9746 - val_loss: 0.1328 - val_accuracy: 0.9537\n",
      "Epoch 721/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0616 - accuracy: 0.9769 - val_loss: 0.1570 - val_accuracy: 0.9537\n",
      "Epoch 722/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0665 - accuracy: 0.9769 - val_loss: 0.1469 - val_accuracy: 0.9398\n",
      "Epoch 723/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0494 - accuracy: 0.9885 - val_loss: 0.1474 - val_accuracy: 0.9491\n",
      "Epoch 724/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0531 - accuracy: 0.9815 - val_loss: 0.1431 - val_accuracy: 0.9537\n",
      "Epoch 725/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0550 - accuracy: 0.9781 - val_loss: 0.1958 - val_accuracy: 0.9444\n",
      "Epoch 726/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0534 - accuracy: 0.9815 - val_loss: 0.1589 - val_accuracy: 0.9444\n",
      "Epoch 727/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0610 - accuracy: 0.9827 - val_loss: 0.1151 - val_accuracy: 0.9583\n",
      "Epoch 728/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.1336 - val_accuracy: 0.9537\n",
      "Epoch 729/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0502 - accuracy: 0.9838 - val_loss: 0.1506 - val_accuracy: 0.9491\n",
      "Epoch 730/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0391 - accuracy: 0.9873 - val_loss: 0.1544 - val_accuracy: 0.9491\n",
      "Epoch 731/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0354 - accuracy: 0.9908 - val_loss: 0.1328 - val_accuracy: 0.9537\n",
      "Epoch 732/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0760 - accuracy: 0.9769 - val_loss: 0.1160 - val_accuracy: 0.9583\n",
      "Epoch 733/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0416 - accuracy: 0.9885 - val_loss: 0.1615 - val_accuracy: 0.9491\n",
      "Epoch 734/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0491 - accuracy: 0.9861 - val_loss: 0.1319 - val_accuracy: 0.9444\n",
      "Epoch 735/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0517 - accuracy: 0.9804 - val_loss: 0.1225 - val_accuracy: 0.9537\n",
      "Epoch 736/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0465 - accuracy: 0.9873 - val_loss: 0.1409 - val_accuracy: 0.9444\n",
      "Epoch 737/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0319 - accuracy: 0.9919 - val_loss: 0.1452 - val_accuracy: 0.9491\n",
      "Epoch 738/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0301 - accuracy: 0.9861 - val_loss: 0.1296 - val_accuracy: 0.9537\n",
      "Epoch 739/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0287 - accuracy: 0.9919 - val_loss: 0.1559 - val_accuracy: 0.9444\n",
      "Epoch 740/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 0.1522 - val_accuracy: 0.9583\n",
      "Epoch 741/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0331 - accuracy: 0.9861 - val_loss: 0.1280 - val_accuracy: 0.9537\n",
      "Epoch 742/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0293 - accuracy: 0.9931 - val_loss: 0.1271 - val_accuracy: 0.9583\n",
      "Epoch 743/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0233 - accuracy: 0.9919 - val_loss: 0.1492 - val_accuracy: 0.9491\n",
      "Epoch 744/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.1326 - val_accuracy: 0.9537\n",
      "Epoch 745/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0327 - accuracy: 0.9931 - val_loss: 0.1293 - val_accuracy: 0.9583\n",
      "Epoch 746/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0345 - accuracy: 0.9896 - val_loss: 0.1692 - val_accuracy: 0.9444\n",
      "Epoch 747/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.1510 - val_accuracy: 0.9491\n",
      "Epoch 748/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 0.1724 - val_accuracy: 0.9491\n",
      "Epoch 749/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 0.1530 - val_accuracy: 0.9491\n",
      "Epoch 750/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0357 - accuracy: 0.9885 - val_loss: 0.1241 - val_accuracy: 0.9583\n",
      "Epoch 751/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0266 - accuracy: 0.9896 - val_loss: 0.1518 - val_accuracy: 0.9630\n",
      "Epoch 752/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.1707 - val_accuracy: 0.9583\n",
      "Epoch 753/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0439 - accuracy: 0.9873 - val_loss: 0.1773 - val_accuracy: 0.9491\n",
      "Epoch 754/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.1394 - val_accuracy: 0.9630\n",
      "Epoch 755/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0179 - accuracy: 0.9954 - val_loss: 0.1741 - val_accuracy: 0.9537\n",
      "Epoch 756/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0264 - accuracy: 0.9885 - val_loss: 0.1249 - val_accuracy: 0.9537\n",
      "Epoch 757/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.1692 - val_accuracy: 0.9583\n",
      "Epoch 758/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.1501 - val_accuracy: 0.9583\n",
      "Epoch 759/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0148 - accuracy: 0.9942 - val_loss: 0.1753 - val_accuracy: 0.9491\n",
      "Epoch 760/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0131 - accuracy: 0.9942 - val_loss: 0.1981 - val_accuracy: 0.9537\n",
      "Epoch 761/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.1704 - val_accuracy: 0.9583\n",
      "Epoch 762/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.1859 - val_accuracy: 0.9583\n",
      "Epoch 763/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.1763 - val_accuracy: 0.9630\n",
      "Epoch 764/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.1748 - val_accuracy: 0.9583\n",
      "Epoch 765/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 0.1698 - val_accuracy: 0.9491\n",
      "Epoch 766/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.1837 - val_accuracy: 0.9537\n",
      "Epoch 767/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.1564 - val_accuracy: 0.9583\n",
      "Epoch 768/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0205 - accuracy: 0.9965 - val_loss: 0.1752 - val_accuracy: 0.9537\n",
      "Epoch 769/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.1787 - val_accuracy: 0.9583\n",
      "Epoch 770/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.1822 - val_accuracy: 0.9491\n",
      "Epoch 771/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.2016 - val_accuracy: 0.9537\n",
      "Epoch 772/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0250 - accuracy: 0.9965 - val_loss: 0.2116 - val_accuracy: 0.9583\n",
      "Epoch 773/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0167 - accuracy: 0.9954 - val_loss: 0.1790 - val_accuracy: 0.9630\n",
      "Epoch 774/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.1863 - val_accuracy: 0.9630\n",
      "Epoch 775/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.1879 - val_accuracy: 0.9583\n",
      "Epoch 776/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.1759 - val_accuracy: 0.9583\n",
      "Epoch 777/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.1823 - val_accuracy: 0.9537\n",
      "Epoch 778/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.1732 - val_accuracy: 0.9583\n",
      "Epoch 779/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.1981 - val_accuracy: 0.9537\n",
      "Epoch 780/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0276 - accuracy: 0.9896 - val_loss: 0.2171 - val_accuracy: 0.9583\n",
      "Epoch 781/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 0.1808 - val_accuracy: 0.9583\n",
      "Epoch 782/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1878 - val_accuracy: 0.9537\n",
      "Epoch 783/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0255 - accuracy: 0.9942 - val_loss: 0.1597 - val_accuracy: 0.9537\n",
      "Epoch 784/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 0.1754 - val_accuracy: 0.9630\n",
      "Epoch 785/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.1890 - val_accuracy: 0.9583\n",
      "Epoch 786/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.1964 - val_accuracy: 0.9630\n",
      "Epoch 787/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.1923 - val_accuracy: 0.9491\n",
      "Epoch 788/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0192 - accuracy: 0.9919 - val_loss: 0.1924 - val_accuracy: 0.9491\n",
      "Epoch 789/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.1751 - val_accuracy: 0.9537\n",
      "Epoch 790/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0109 - accuracy: 0.9977 - val_loss: 0.1756 - val_accuracy: 0.9630\n",
      "Epoch 791/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.1976 - val_accuracy: 0.9630\n",
      "Epoch 792/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.1961 - val_accuracy: 0.9583\n",
      "Epoch 793/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0174 - accuracy: 0.9977 - val_loss: 0.1777 - val_accuracy: 0.9583\n",
      "Epoch 794/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1849 - val_accuracy: 0.9722\n",
      "Epoch 795/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.1976 - val_accuracy: 0.9537\n",
      "Epoch 796/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9583\n",
      "Epoch 797/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.2073 - val_accuracy: 0.9583\n",
      "Epoch 798/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.1959 - val_accuracy: 0.9583\n",
      "Epoch 799/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0076 - accuracy: 0.9988 - val_loss: 0.2147 - val_accuracy: 0.9537\n",
      "Epoch 800/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.2333 - val_accuracy: 0.9537\n",
      "Epoch 801/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.2001 - val_accuracy: 0.9583\n",
      "Epoch 802/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.2015 - val_accuracy: 0.9630\n",
      "Epoch 803/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9954 - val_loss: 0.2066 - val_accuracy: 0.9583\n",
      "Epoch 804/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.1985 - val_accuracy: 0.9583\n",
      "Epoch 805/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.1784 - val_accuracy: 0.9630\n",
      "Epoch 806/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0145 - accuracy: 0.9942 - val_loss: 0.1688 - val_accuracy: 0.9630\n",
      "Epoch 807/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.1958 - val_accuracy: 0.9583\n",
      "Epoch 808/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0170 - accuracy: 0.9977 - val_loss: 0.2079 - val_accuracy: 0.9583\n",
      "Epoch 809/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.1913 - val_accuracy: 0.9722\n",
      "Epoch 810/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.1954 - val_accuracy: 0.9676\n",
      "Epoch 811/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.2079 - val_accuracy: 0.9630\n",
      "Epoch 812/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.2256 - val_accuracy: 0.9676\n",
      "Epoch 813/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9988 - val_loss: 0.2249 - val_accuracy: 0.9630\n",
      "Epoch 814/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.2259 - val_accuracy: 0.9583\n",
      "Epoch 815/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.2301 - val_accuracy: 0.9630\n",
      "Epoch 816/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.2191 - val_accuracy: 0.9630\n",
      "Epoch 817/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0061 - accuracy: 0.9965 - val_loss: 0.2387 - val_accuracy: 0.9630\n",
      "Epoch 818/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0567 - accuracy: 0.9815 - val_loss: 0.1957 - val_accuracy: 0.9583\n",
      "Epoch 819/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0104 - accuracy: 0.9942 - val_loss: 0.2096 - val_accuracy: 0.9583\n",
      "Epoch 820/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0105 - accuracy: 0.9954 - val_loss: 0.2250 - val_accuracy: 0.9491\n",
      "Epoch 821/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.2129 - val_accuracy: 0.9583\n",
      "Epoch 822/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.2082 - val_accuracy: 0.9537\n",
      "Epoch 823/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 0.2227 - val_accuracy: 0.9630\n",
      "Epoch 824/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.2240 - val_accuracy: 0.9722\n",
      "Epoch 825/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2398 - val_accuracy: 0.9583\n",
      "Epoch 826/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0242 - accuracy: 0.9873 - val_loss: 0.2513 - val_accuracy: 0.9537\n",
      "Epoch 827/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.2235 - val_accuracy: 0.9583\n",
      "Epoch 828/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.2275 - val_accuracy: 0.9583\n",
      "Epoch 829/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.2274 - val_accuracy: 0.9537\n",
      "Epoch 830/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0078 - accuracy: 0.9965 - val_loss: 0.2193 - val_accuracy: 0.9630\n",
      "Epoch 831/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.2157 - val_accuracy: 0.9630\n",
      "Epoch 832/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9630\n",
      "Epoch 833/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.2315 - val_accuracy: 0.9630\n",
      "Epoch 834/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.2586 - val_accuracy: 0.9630\n",
      "Epoch 835/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9630\n",
      "Epoch 836/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.2282 - val_accuracy: 0.9583\n",
      "Epoch 837/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 0.2261 - val_accuracy: 0.9630\n",
      "Epoch 838/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9977 - val_loss: 0.2571 - val_accuracy: 0.9583\n",
      "Epoch 839/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9676\n",
      "Epoch 840/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0069 - accuracy: 0.9965 - val_loss: 0.2494 - val_accuracy: 0.9630\n",
      "Epoch 841/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0215 - accuracy: 0.9919 - val_loss: 0.1872 - val_accuracy: 0.9630\n",
      "Epoch 842/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.2196 - val_accuracy: 0.9583\n",
      "Epoch 843/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9722\n",
      "Epoch 844/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.2245 - val_accuracy: 0.9676\n",
      "Epoch 845/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9630\n",
      "Epoch 846/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.1876 - val_accuracy: 0.9630\n",
      "Epoch 847/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1818 - val_accuracy: 0.9676\n",
      "Epoch 848/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9722\n",
      "Epoch 849/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1894 - val_accuracy: 0.9676\n",
      "Epoch 850/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.2084 - val_accuracy: 0.9630\n",
      "Epoch 851/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.2124 - val_accuracy: 0.9722\n",
      "Epoch 852/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2221 - val_accuracy: 0.9630\n",
      "Epoch 853/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2154 - val_accuracy: 0.9676\n",
      "Epoch 854/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.2237 - val_accuracy: 0.9676\n",
      "Epoch 855/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2130 - val_accuracy: 0.9676\n",
      "Epoch 856/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0156 - accuracy: 0.9919 - val_loss: 0.2406 - val_accuracy: 0.9630\n",
      "Epoch 857/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9630\n",
      "Epoch 858/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.2463 - val_accuracy: 0.9630\n",
      "Epoch 859/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9630\n",
      "Epoch 860/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.2214 - val_accuracy: 0.9630\n",
      "Epoch 861/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 0.9722\n",
      "Epoch 862/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.3505 - val_accuracy: 0.9537\n",
      "Epoch 863/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0108 - accuracy: 0.9942 - val_loss: 0.2638 - val_accuracy: 0.9630\n",
      "Epoch 864/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9676\n",
      "Epoch 865/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9965 - val_loss: 0.2622 - val_accuracy: 0.9583\n",
      "Epoch 866/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9583\n",
      "Epoch 867/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.2862 - val_accuracy: 0.9676\n",
      "Epoch 868/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2777 - val_accuracy: 0.9630\n",
      "Epoch 869/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9630\n",
      "Epoch 870/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0054 - accuracy: 0.9965 - val_loss: 0.2894 - val_accuracy: 0.9630\n",
      "Epoch 871/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.2690 - val_accuracy: 0.9676\n",
      "Epoch 872/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0045 - accuracy: 0.9977 - val_loss: 0.2644 - val_accuracy: 0.9676\n",
      "Epoch 873/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.2684 - val_accuracy: 0.9630\n",
      "Epoch 874/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.2476 - val_accuracy: 0.9676\n",
      "Epoch 875/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.2514 - val_accuracy: 0.9722\n",
      "Epoch 876/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.2730 - val_accuracy: 0.9676\n",
      "Epoch 877/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0050 - accuracy: 0.9977 - val_loss: 0.2767 - val_accuracy: 0.9630\n",
      "Epoch 878/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0088 - accuracy: 0.9954 - val_loss: 0.2994 - val_accuracy: 0.9630\n",
      "Epoch 879/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0329 - accuracy: 0.9908 - val_loss: 0.2283 - val_accuracy: 0.9583\n",
      "Epoch 880/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.2655 - val_accuracy: 0.9630\n",
      "Epoch 881/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9630\n",
      "Epoch 882/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.2441 - val_accuracy: 0.9630\n",
      "Epoch 883/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0061 - accuracy: 0.9977 - val_loss: 0.2245 - val_accuracy: 0.9630\n",
      "Epoch 884/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0117 - accuracy: 0.9988 - val_loss: 0.2565 - val_accuracy: 0.9583\n",
      "Epoch 885/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0119 - accuracy: 0.9931 - val_loss: 0.2319 - val_accuracy: 0.9537\n",
      "Epoch 886/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.2515 - val_accuracy: 0.9583\n",
      "Epoch 887/1000\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.2381 - val_accuracy: 0.9583\n",
      "Epoch 888/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9583\n",
      "Epoch 889/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.2512 - val_accuracy: 0.9630\n",
      "Epoch 890/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9630\n",
      "Epoch 891/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.2612 - val_accuracy: 0.9676\n",
      "Epoch 892/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.2554 - val_accuracy: 0.9676\n",
      "Epoch 893/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9630\n",
      "Epoch 894/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9676\n",
      "Epoch 895/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.2498 - val_accuracy: 0.9722\n",
      "Epoch 896/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.2518 - val_accuracy: 0.9769\n",
      "Epoch 897/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.2899 - val_accuracy: 0.9630\n",
      "Epoch 898/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2672 - val_accuracy: 0.9722\n",
      "Epoch 899/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 0.9676\n",
      "Epoch 900/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.2730 - val_accuracy: 0.9630\n",
      "Epoch 901/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9630\n",
      "Epoch 902/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0271 - accuracy: 0.9942 - val_loss: 0.2926 - val_accuracy: 0.9537\n",
      "Epoch 903/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0212 - accuracy: 0.9954 - val_loss: 0.3145 - val_accuracy: 0.9583\n",
      "Epoch 904/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.3254 - val_accuracy: 0.9583\n",
      "Epoch 905/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3204 - val_accuracy: 0.9583\n",
      "Epoch 906/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0065 - accuracy: 0.9965 - val_loss: 0.3074 - val_accuracy: 0.9583\n",
      "Epoch 907/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.3554 - val_accuracy: 0.9537\n",
      "Epoch 908/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.3171 - val_accuracy: 0.9630\n",
      "Epoch 909/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9630\n",
      "Epoch 910/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.2863 - val_accuracy: 0.9537\n",
      "Epoch 911/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.3147 - val_accuracy: 0.9630\n",
      "Epoch 912/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.3183 - val_accuracy: 0.9630\n",
      "Epoch 913/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.3700 - val_accuracy: 0.9583\n",
      "Epoch 914/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.3315 - val_accuracy: 0.9630\n",
      "Epoch 915/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.2831 - val_accuracy: 0.9676\n",
      "Epoch 916/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9676\n",
      "Epoch 917/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9676\n",
      "Epoch 918/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.2884 - val_accuracy: 0.9676\n",
      "Epoch 919/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9583\n",
      "Epoch 920/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.4073 - val_accuracy: 0.9491\n",
      "Epoch 921/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.3144 - val_accuracy: 0.9630\n",
      "Epoch 922/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.2761 - val_accuracy: 0.9583\n",
      "Epoch 923/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 0.9630\n",
      "Epoch 924/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 0.2875 - val_accuracy: 0.9676\n",
      "Epoch 925/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.2803 - val_accuracy: 0.9630\n",
      "Epoch 926/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0120 - accuracy: 0.9954 - val_loss: 0.2925 - val_accuracy: 0.9630\n",
      "Epoch 927/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 0.9583\n",
      "Epoch 928/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.2920 - val_accuracy: 0.9583\n",
      "Epoch 929/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.2793 - val_accuracy: 0.9630\n",
      "Epoch 930/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9630\n",
      "Epoch 931/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2923 - val_accuracy: 0.9676\n",
      "Epoch 932/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.9630\n",
      "Epoch 933/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.3456 - val_accuracy: 0.9630\n",
      "Epoch 934/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.3211 - val_accuracy: 0.9491\n",
      "Epoch 935/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.2829 - val_accuracy: 0.9583\n",
      "Epoch 936/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9.3991e-04 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9630\n",
      "Epoch 937/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9676\n",
      "Epoch 938/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0035 - accuracy: 0.9977 - val_loss: 0.2785 - val_accuracy: 0.9630\n",
      "Epoch 939/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.2613 - val_accuracy: 0.9630\n",
      "Epoch 940/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.2654 - val_accuracy: 0.9676\n",
      "Epoch 941/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9676\n",
      "Epoch 942/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 7.9205e-04 - accuracy: 1.0000 - val_loss: 0.2738 - val_accuracy: 0.9583\n",
      "Epoch 943/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9630\n",
      "Epoch 944/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 4.2777e-04 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9630\n",
      "Epoch 945/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.2600 - val_accuracy: 0.9676\n",
      "Epoch 946/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 0.3273 - val_accuracy: 0.9583\n",
      "Epoch 947/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0569 - accuracy: 0.9850 - val_loss: 0.2256 - val_accuracy: 0.9630\n",
      "Epoch 948/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.1947 - val_accuracy: 0.9583\n",
      "Epoch 949/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.2217 - val_accuracy: 0.9630\n",
      "Epoch 950/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0047 - accuracy: 0.9977 - val_loss: 0.2255 - val_accuracy: 0.9583\n",
      "Epoch 951/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9537\n",
      "Epoch 952/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.2294 - val_accuracy: 0.9583\n",
      "Epoch 953/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9583\n",
      "Epoch 954/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2390 - val_accuracy: 0.9630\n",
      "Epoch 955/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.2421 - val_accuracy: 0.9630\n",
      "Epoch 956/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0201 - accuracy: 0.9965 - val_loss: 0.3112 - val_accuracy: 0.9537\n",
      "Epoch 957/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2728 - val_accuracy: 0.9537\n",
      "Epoch 958/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.2909 - val_accuracy: 0.9583\n",
      "Epoch 959/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 0.2825 - val_accuracy: 0.9630\n",
      "Epoch 960/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.2844 - val_accuracy: 0.9537\n",
      "Epoch 961/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 0.9537\n",
      "Epoch 962/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9537\n",
      "Epoch 963/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0050 - accuracy: 0.9965 - val_loss: 0.2664 - val_accuracy: 0.9583\n",
      "Epoch 964/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9583\n",
      "Epoch 965/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9583\n",
      "Epoch 966/1000\n",
      "28/28 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9583\n",
      "Epoch 967/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2996 - val_accuracy: 0.9537\n",
      "Epoch 968/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9537\n",
      "Epoch 969/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.2673 - val_accuracy: 0.9491\n",
      "Epoch 970/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9630\n",
      "Epoch 971/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9537\n",
      "Epoch 972/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 9.8510e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9583\n",
      "Epoch 973/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0046 - accuracy: 0.9977 - val_loss: 0.2872 - val_accuracy: 0.9630\n",
      "Epoch 974/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9583\n",
      "Epoch 975/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9583\n",
      "Epoch 976/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9583\n",
      "Epoch 977/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3137 - val_accuracy: 0.9583\n",
      "Epoch 978/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.9444\n",
      "Epoch 979/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9491\n",
      "Epoch 980/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0039 - accuracy: 0.9977 - val_loss: 0.2694 - val_accuracy: 0.9676\n",
      "Epoch 981/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 9.4393e-04 - accuracy: 1.0000 - val_loss: 0.2823 - val_accuracy: 0.9630\n",
      "Epoch 982/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.2927 - val_accuracy: 0.9537\n",
      "Epoch 983/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3148 - val_accuracy: 0.9537\n",
      "Epoch 984/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9583\n",
      "Epoch 985/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.9583\n",
      "Epoch 986/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3224 - val_accuracy: 0.9537\n",
      "Epoch 987/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9676\n",
      "Epoch 988/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 0.9537\n",
      "Epoch 989/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.2814 - val_accuracy: 0.9630\n",
      "Epoch 990/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0062 - accuracy: 0.9965 - val_loss: 0.3444 - val_accuracy: 0.9583\n",
      "Epoch 991/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.2916 - val_accuracy: 0.9583\n",
      "Epoch 992/1000\n",
      "28/28 [==============================] - 1s 28ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.2840 - val_accuracy: 0.9537\n",
      "Epoch 993/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.2893 - val_accuracy: 0.9583\n",
      "Epoch 994/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.9537\n",
      "Epoch 995/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.3251 - val_accuracy: 0.9583\n",
      "Epoch 996/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.2998 - val_accuracy: 0.9583\n",
      "Epoch 997/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0027 - accuracy: 0.9977 - val_loss: 0.2998 - val_accuracy: 0.9630\n",
      "Epoch 998/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.3148 - val_accuracy: 0.9630\n",
      "Epoch 999/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3081 - val_accuracy: 0.9630\n",
      "Epoch 1000/1000\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.3108 - val_accuracy: 0.9630\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "#### ðŸ”Ž CNN Model Evaluation ðŸ”\n",
    "\n",
    "---\n",
    "\n",
    "> For this task, you'll evaluate your CNN model using the validation dataset in order to calculate overall validation accuracy and loss.\n",
    "> \n",
    "> As always, refer to previous notebooks, tutorials, and documentation for using the proper evaluation function for model prediction. \n",
    "\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "\"\"\" CNN Model Predictive Evaluation \"\"\"\n",
    "model.evaluate(validation)\n",
    "\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Training/Validation Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Training/Validation Loss\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7/7 [==============================] - 0s 9ms/step - loss: 0.3108 - accuracy: 0.9630\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ðŸ”¹ Model State Saving\n",
    "\n",
    "When you are satisfied with your model state configuration and performance and are ready to export the model's weights and parameters for deployment purposes, simply run the following function! "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def save_model(model, file_name, save_format):\n",
    "    \"\"\" \n",
    "    Save the model weights and architecture.\n",
    "    \n",
    "    Parameters: \n",
    "       model(Model): keras Model object being saved\n",
    "       file_name(str): name of the Hadoop file where\n",
    "                       the whole model will be saved\n",
    "       save_format(str): Indicates whether to save the model to the default\n",
    "                         SavedModel('tf'), or HDF5('h5'), or \n",
    "                         use both H5 and JSON ('composite') formats. \n",
    "       Returns: None\n",
    "    \"\"\"\n",
    "    MODEL_DIRECTORY = \"../model\"\n",
    "    def __save_as_composite():\n",
    "      \"\"\" Saving the model as H5 (for params) + JSON (for the architecture) \"\"\"\n",
    "      # Save the weights\n",
    "      model.save_weights(f'{MODEL_DIRECTORY}/{file_name}_params.h5')\n",
    "      # Save the architecture\n",
    "      with open(f'{MODEL_DIRECTORY}/{file_name}_layers.json', 'w') as f:\n",
    "          f.write(model.to_json())\n",
    "    \n",
    "    def __save_as_h5():\n",
    "      \"\"\" Option 2: Saving whole model as a single H5 file (more storage) \"\"\"\n",
    "      model.save(f\"{MODEL_DIRECTORY}/{file_name}.h5\", save_format=save_format)\n",
    "\n",
    "    # Call the appropiate save func\n",
    "    if save_format == 'h5':\n",
    "      __save_as_h5()\n",
    "    elif save_format == 'composite':\n",
    "      __save_as_composite()\n",
    "    else:  # save as a SavedModel\n",
    "      model.save(file_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "save_model(model, \"fire_cnn_classifier\", \"composite\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now go ahead and complete the remaining tasks in `project/PROJECT.md` to complete this project successfully! "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "---"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "1c97728668f4171dac4d51af5a110c1aa39140bd5ccb4af253cef75f1be69431"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}